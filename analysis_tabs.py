import warnings
warnings.filterwarnings('ignore', category=FutureWarning, module='pandas')
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import time
import hashlib
import gc
import logging

# çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from unified_filters import (
    create_unified_filter_sidebar, 
    apply_unified_filters, 
    get_unified_filter_summary,
    initialize_unified_filters,
    validate_unified_filters
)

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils import safe_date_filter

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    # ALOSåˆ†æé–¢é€£
    from alos_analysis_tab import display_alos_analysis_tab
    
    # æ›œæ—¥åˆ¥åˆ†æé–¢é€£
    from dow_analysis_tab import display_dow_analysis_tab
    
    # å€‹åˆ¥åˆ†æé–¢é€£
    from individual_analysis_tab import display_individual_analysis_tab
    
    # äºˆæ¸¬åˆ†æé–¢é€£
    from forecast_analysis_tab import display_forecast_analysis_tab
    
    # ãƒãƒ£ãƒ¼ãƒˆä½œæˆé–¢é€£
    from chart import (
        create_interactive_patient_chart, 
        create_interactive_dual_axis_chart,
        create_forecast_comparison_chart
    )
    
    # PDFç”Ÿæˆé–¢é€£
    from pdf_generator import create_pdf, create_landscape_pdf
    
    # äºˆæ¸¬ãƒ»é›†è¨ˆé–¢é€£
    from forecast import generate_filtered_summaries, create_forecast_dataframe
    
    # KPIè¨ˆç®—é–¢é€£
    from kpi_calculator import calculate_kpis, analyze_kpi_insights
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
    from utils import get_display_name_for_dept
    
except ImportError as e:
    st.error(f"å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼é–¢æ•°ã‚’å®šç¾©
    display_alos_analysis_tab = None
    display_dow_analysis_tab = None
    display_individual_analysis_tab = None
    display_forecast_analysis_tab = None
    create_interactive_patient_chart = None
    create_interactive_dual_axis_chart = None
    create_forecast_comparison_chart = None
    create_pdf = None
    create_landscape_pdf = None
    generate_filtered_summaries = None
    create_forecast_dataframe = None
    calculate_kpis = None
    analyze_kpi_insights = None
    get_display_name_for_dept = None

logger = logging.getLogger(__name__)

# ===============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°ç¾¤ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰
# ===============================================================================
def create_detailed_analysis_tab():
    """è©³ç´°åˆ†æã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.header("ğŸ“ˆ è©³ç´°åˆ†æ")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®åˆæœŸåŒ–
    initialize_unified_filters(df)
    
    # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½œæˆ
    filter_config = create_unified_filter_sidebar(df)
    if filter_config is None:
        st.error("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    is_valid, validation_message = validate_unified_filters(df)
    if not is_valid:
        st.error(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: {validation_message}")
        return
    
    # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    df_filtered = apply_unified_filters(df)
    
    if df_filtered.empty:
        st.warning("é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã®è¡¨ç¤º
    filter_summary = get_unified_filter_summary()
    data_count = len(df_filtered)
    st.info(f"ğŸ” {filter_summary}")
    st.success(f"ğŸ“Š è©²å½“ãƒ‡ãƒ¼ã‚¿: {data_count:,}è¡Œ")
    
    # å…±é€šè¨­å®šã®å–å¾—
    common_config = st.session_state.get('common_config', {})
    
    # ã‚µãƒ–ã‚¿ãƒ–ã®ä½œæˆ
    los_tab, weekday_tab, individual_tab = st.tabs([
        "ğŸ“Š å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ", 
        "ğŸ“… æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ", 
        "ğŸ” å€‹åˆ¥åˆ†æ"
    ])
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¨è¨­å®šã‚’å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«æ¸¡ã™
    with los_tab:
        create_los_analysis_section(df_filtered, filter_config, common_config)
    
    with weekday_tab:
        create_weekday_analysis_section(df_filtered, filter_config, common_config)
    
    with individual_tab:
        create_individual_analysis_section(df_filtered, filter_config)

def create_data_tables_tab():
    """ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.header("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    df_filtered = apply_unified_filters(df)
    filter_summary = get_unified_filter_summary()
    st.info(f"ğŸ” {filter_summary}")
    
    if df_filtered.empty:
        st.warning("é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚µãƒ–ã‚¿ãƒ–ã®ä½œæˆ
    ward_table_tab, dept_table_tab = st.tabs([
        "ğŸ¥ ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«", 
        "ğŸ©º è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"
    ])
    
    with ward_table_tab:
        create_ward_table_section(df_filtered)
    
    with dept_table_tab:
        create_department_table_section(df_filtered)

def create_output_prediction_tab():
    """å‡ºåŠ›ãƒ»äºˆæ¸¬ã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.header("ğŸ“„ å‡ºåŠ›ãƒ»äºˆæ¸¬")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    df_filtered = apply_unified_filters(df)
    filter_summary = get_unified_filter_summary()
    st.info(f"ğŸ” å‡ºåŠ›ãƒ»äºˆæ¸¬æœŸé–“: {filter_summary}")
    
    if df_filtered.empty:
        st.warning("é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚µãƒ–ã‚¿ãƒ–ã®ä½œæˆ
    individual_pdf_tab, bulk_pdf_tab, prediction_tab = st.tabs([
        "ğŸ“„ å€‹åˆ¥PDFå‡ºåŠ›", 
        "ğŸ“š ä¸€æ‹¬PDFå‡ºåŠ›", 
        "ğŸ”® äºˆæ¸¬åˆ†æ"
    ])
    
    with individual_pdf_tab:
        create_individual_pdf_section(df_filtered)
    
    with bulk_pdf_tab:
        create_bulk_pdf_section(df_filtered)
    
    with prediction_tab:
        create_prediction_analysis_section(df_filtered)

# ===============================================================================
# è©³ç´°åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰
# ===============================================================================

def create_los_analysis_section(df_filtered, filter_config, common_config):
    """å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ“Š å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ")
    
    if display_alos_analysis_tab:
        try:
            # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
            display_alos_analysis_tab(df_filtered, filter_config, common_config)
            
        except Exception as e:
            logger.error(f"å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚alos_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_los_analysis(df_filtered, filter_config)

def create_weekday_analysis_section(df_filtered, filter_config, common_config):
    """æ›œæ—¥åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ“… æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ")
    
    if display_dow_analysis_tab:
        try:
            # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
            display_dow_analysis_tab(df_filtered, filter_config, common_config)
        except Exception as e:
            logger.error(f"æ›œæ—¥åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"æ›œæ—¥åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("æ›œæ—¥åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚dow_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_dow_analysis(df_filtered, filter_config)

def create_individual_analysis_section(df_filtered, filter_config):
    """å€‹åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ” å€‹åˆ¥åˆ†æ")
    
    if display_individual_analysis_tab:
        try:
            # å€‹åˆ¥åˆ†æç”¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¸€æ™‚çš„ã«æ›´æ–°
            original_df = st.session_state.get('df')
            st.session_state['df'] = df_filtered  # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
            st.session_state['unified_filter_applied'] = True  # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ãƒ•ãƒ©ã‚°
            st.session_state['current_filter_config'] = filter_config  # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã‚’ä¿å­˜
            
            # å€‹åˆ¥åˆ†æå®Ÿè¡Œ
            display_individual_analysis_tab()
            
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
            st.session_state['df'] = original_df
            st.session_state['unified_filter_applied'] = False
            
        except Exception as e:
            logger.error(f"å€‹åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"å€‹åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        finally:
            # å¿µã®ãŸã‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
            if 'original_df' in locals():
                st.session_state['df'] = original_df
                st.session_state['unified_filter_applied'] = False
    else:
        st.warning("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚individual_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_individual_analysis(df_filtered, filter_config)

# ===============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰
# ===============================================================================

def create_ward_table_section(df_filtered):
    """ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ¥ ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    try:
        if df_filtered.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # ç—…æ£Ÿãƒãƒƒãƒ”ãƒ³ã‚°ã®åˆæœŸåŒ–
        from utils import initialize_all_mappings, get_ward_display_name
        initialize_all_mappings(df_filtered)
        ward_mapping = st.session_state.get('ward_mapping', {})
        
        # æœŸé–“æƒ…å ±ã®è¡¨ç¤º
        if 'æ—¥ä»˜' in df_filtered.columns:
            min_date = df_filtered['æ—¥ä»˜'].min().date()
            max_date = df_filtered['æ—¥ä»˜'].max().date()
            st.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        
        # ç—…æ£Ÿåˆ¥é›†è¨ˆ
        ward_summary = calculate_ward_summary(df_filtered)
        
        if not ward_summary.empty:
            # ç—…æ£Ÿååˆ—ã‚’è¿½åŠ 
            ward_summary['ç—…æ£Ÿå'] = ward_summary['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].apply(
                lambda x: get_ward_display_name(x, ward_mapping)
            )
            
            # åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆç—…æ£Ÿåã‚’ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã®å¾Œã«é…ç½®ï¼‰
            cols = ward_summary.columns.tolist()
            if 'ç—…æ£Ÿå' in cols:
                # ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã®å¾Œã«ç—…æ£Ÿåã‚’é…ç½®
                code_idx = cols.index('ç—…æ£Ÿã‚³ãƒ¼ãƒ‰')
                cols.insert(code_idx + 1, cols.pop(cols.index('ç—…æ£Ÿå')))
                ward_summary = ward_summary[cols]
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã¨å‡¦ç†
            display_ward_table_with_filters(ward_summary, df_filtered)
            
            # ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•
            create_ward_comparison_charts(ward_summary)
        else:
            st.warning("ç—…æ£Ÿåˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
    except Exception as e:
        logger.error(f"ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def create_department_table_section(df_filtered):
    """è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ©º è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    try:
        if df_filtered.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æœŸé–“æƒ…å ±ã®è¡¨ç¤º
        if 'æ—¥ä»˜' in df_filtered.columns:
            min_date = df_filtered['æ—¥ä»˜'].min().date()
            max_date = df_filtered['æ—¥ä»˜'].max().date()
            st.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        
        # è¨ºç™‚ç§‘åˆ¥é›†è¨ˆ
        dept_summary = calculate_department_summary(df_filtered)
        
        if not dept_summary.empty:
            # è¨ºç™‚ç§‘åã®è¡¨ç¤ºåå¤‰æ›
            if get_display_name_for_dept:
                dept_summary['è¨ºç™‚ç§‘è¡¨ç¤ºå'] = dept_summary['è¨ºç™‚ç§‘å'].apply(
                    lambda x: get_display_name_for_dept(x, default_name=x)
                )
                # è¡¨ç¤ºç”¨ã«åˆ—ã®é †åºã‚’èª¿æ•´
                cols = dept_summary.columns.tolist()
                if 'è¨ºç™‚ç§‘è¡¨ç¤ºå' in cols:
                    cols.insert(1, cols.pop(cols.index('è¨ºç™‚ç§‘è¡¨ç¤ºå')))
                    dept_summary = dept_summary[cols]
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã¨å‡¦ç†
            display_department_table_with_filters(dept_summary, df_filtered)
            
            # è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•
            create_department_comparison_charts(dept_summary)
        else:
            st.warning("è¨ºç™‚ç§‘åˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
    except Exception as e:
        logger.error(f"è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ===============================================================================
# ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ===============================================================================

def display_ward_table_with_filters(ward_summary, df_filtered):
    """ç—…æ£Ÿãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡¨ç¤ºã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†"""
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        # é¸æŠè‚¢ã‚’ã€Œã‚³ãƒ¼ãƒ‰ï¼ˆåå‰ï¼‰ã€å½¢å¼ã§è¡¨ç¤º
        ward_display_options = []
        for _, row in ward_summary.iterrows():
            code = row['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰']
            name = row['ç—…æ£Ÿå']
            if name != str(code):
                display_option = f"{code}ï¼ˆ{name}ï¼‰"
            else:
                display_option = str(code)
            ward_display_options.append(display_option)
        
        selected_wards = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹ç—…æ£Ÿã‚’é¸æŠï¼ˆç©ºç™½ã®å ´åˆã¯å…¨ã¦è¡¨ç¤ºï¼‰",
            options=ward_display_options,
            key="ward_table_filter"
        )
    
    with col2:
        sort_column = st.selectbox(
            "ä¸¦ã³æ›¿ãˆåŸºæº–",
            options=['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°'],
            key="ward_table_sort"
        )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆ
    display_summary = ward_summary.copy()
    if selected_wards:
        # é¸æŠã•ã‚ŒãŸè¡¨ç¤ºåã‹ã‚‰ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        selected_codes = []
        for display_ward in selected_wards:
            # ã€Œã‚³ãƒ¼ãƒ‰ï¼ˆåå‰ï¼‰ã€å½¢å¼ã‹ã‚‰ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            if 'ï¼ˆ' in display_ward:
                code = display_ward.split('ï¼ˆ')[0]
            else:
                code = display_ward
            selected_codes.append(code)
        display_summary = display_summary[display_summary['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].isin(selected_codes)]
    
    if sort_column in display_summary.columns:
        ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã³æ›¿ãˆ", key="ward_table_ascending")
        display_summary = display_summary.sort_values(sort_column, ascending=ascending)
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨ã¨ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    format_dict = create_table_format_dict(display_summary)
    st.dataframe(
        display_summary.style.format(format_dict),
        use_container_width=True,
        height=400
    )
    
    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    create_csv_download_button(display_summary, df_filtered, "ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿")

def display_department_table_with_filters(dept_summary, df_filtered):
    """è¨ºç™‚ç§‘ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡¨ç¤ºã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†"""
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        selected_depts = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹è¨ºç™‚ç§‘ã‚’é¸æŠï¼ˆç©ºç™½ã®å ´åˆã¯å…¨ã¦è¡¨ç¤ºï¼‰",
            options=sorted(dept_summary['è¨ºç™‚ç§‘å'].unique()),
            key="dept_table_filter"
        )
    
    with col2:
        sort_column = st.selectbox(
            "ä¸¦ã³æ›¿ãˆåŸºæº–",
            options=['è¨ºç™‚ç§‘å', 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°'],
            key="dept_table_sort"
        )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆ
    display_summary = dept_summary.copy()
    if selected_depts:
        display_summary = display_summary[display_summary['è¨ºç™‚ç§‘å'].isin(selected_depts)]
    
    if sort_column in display_summary.columns:
        ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã³æ›¿ãˆ", key="dept_table_ascending")
        display_summary = display_summary.sort_values(sort_column, ascending=ascending)
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨ã¨ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    format_dict = create_table_format_dict(display_summary)
    st.dataframe(
        display_summary.style.format(format_dict),
        use_container_width=True,
        height=400
    )
    
    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    create_csv_download_button(display_summary, df_filtered, "è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿")

def create_table_format_dict(summary_df):
    """ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¾æ›¸ã®ä½œæˆ"""
    format_dict = {}
    
    for col in summary_df.columns:
        if col in ['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'è¨ºç™‚ç§‘å', 'è¨ºç™‚ç§‘è¡¨ç¤ºå', 'ç—…æ£Ÿå', 'é›†è¨ˆå˜ä½']:
            # æ–‡å­—åˆ—åˆ—ã¯ãã®ã¾ã¾
            continue
        elif col in ['æœŸé–“æ—¥æ•°', 'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 
                   'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°']:
            # æ•´æ•°å€¤ã¨ã—ã¦è¡¨ç¤ºï¼ˆåˆè¨ˆå€¤ãƒ»ã‚«ã‚¦ãƒ³ãƒˆæ•°ï¼‰
            format_dict[col] = "{:.0f}"
        elif col in ['å¹³å‡åœ¨é™¢æ‚£è€…æ•°']:
            # å°æ•°ç‚¹1æ¡ã§è¡¨ç¤ºï¼ˆå¹³å‡å€¤ï¼‰
            format_dict[col] = "{:.1f}"
        elif col in ['å¹³å‡åœ¨é™¢æ—¥æ•°', 'ç—…åºŠå›è»¢ç‡']:
            # å°æ•°ç‚¹1æ¡ã§è¡¨ç¤ºï¼ˆæ¯”ç‡ãƒ»æ—¥æ•°ï¼‰
            format_dict[col] = "{:.1f}"
        elif col in ['ç·Šæ€¥å…¥é™¢ç‡', 'æ­»äº¡ç‡']:
            # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã¯å°æ•°ç‚¹1æ¡ + %
            format_dict[col] = "{:.1f}%"
        else:
            # ãã®ä»–ã®æ•°å€¤åˆ—ã¯å°æ•°ç‚¹1æ¡
            if pd.api.types.is_numeric_dtype(summary_df[col]):
                # æ•´æ•°ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                if summary_df[col].dtype in ['int64', 'int32', 'Int64', 'Int32']:
                    format_dict[col] = "{:.0f}"
                else:
                    # å¹³å‡å€¤ã‹ã©ã†ã‹ã‚’åå‰ã‹ã‚‰åˆ¤å®š
                    if 'å¹³å‡' in col or 'ç‡' in col or 'æ—¥æ•°' in col:
                        format_dict[col] = "{:.1f}"
                    else:
                        format_dict[col] = "{:.0f}"
    
    return format_dict

def create_csv_download_button(summary_df, df_filtered, data_type):
    """CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ä½œæˆ"""
    csv_data = summary_df.to_csv(index=False).encode('utf-8-sig')
    
    # æœŸé–“æ–‡å­—åˆ—ã®ç”Ÿæˆ
    if 'æ—¥ä»˜' in df_filtered.columns:
        min_date = df_filtered['æ—¥ä»˜'].min().date()
        max_date = df_filtered['æ—¥ä»˜'].max().date()
        period_str = f"{min_date}_{max_date}"
    else:
        period_str = "å…¨æœŸé–“"
    
    st.download_button(
        label=f"{data_type}ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_data,
        file_name=f"{data_type}_{period_str}.csv",
        mime="text/csv"
    )

# ===============================================================================
# é›†è¨ˆå‡¦ç†é–¢æ•°ï¼ˆæ—¢å­˜é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
# ===============================================================================

def calculate_ward_summary(df):
    """ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—"""
    try:
        # å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—åã‚’ç¢ºèª
        available_columns = df.columns.tolist()
        
        # åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæŸ”è»Ÿãªå¯¾å¿œï¼‰
        column_mapping = {
            'åœ¨é™¢æ‚£è€…æ•°': ['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'åœ¨é™¢æ‚£è€…æ•°', 'ç¾åœ¨æ‚£è€…æ•°'],
            'å…¥é™¢æ‚£è€…æ•°': ['ç·å…¥é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'æ–°è¦å…¥é™¢æ‚£è€…æ•°'],
            'é€€é™¢æ‚£è€…æ•°': ['ç·é€€é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'é€€é™¢è€…æ•°'],
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ•‘æ€¥å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢'],
            'æ­»äº¡æ‚£è€…æ•°': ['æ­»äº¡æ‚£è€…æ•°', 'æ­»äº¡è€…æ•°', 'æ­»äº¡']
        }
        
        # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹åˆ—åã‚’æ±ºå®š
        actual_columns = {}
        missing_columns = []
        
        for standard_name, possible_names in column_mapping.items():
            found_column = None
            for possible_name in possible_names:
                if possible_name in available_columns:
                    found_column = possible_name
                    break
            
            if found_column:
                actual_columns[standard_name] = found_column
            else:
                missing_columns.append(standard_name)
        
        if missing_columns:
            st.error(f"ç—…æ£Ÿåˆ¥é›†è¨ˆã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
            return pd.DataFrame()
        
        # ç—…æ£Ÿåˆ¥é›†è¨ˆï¼ˆå®Ÿéš›ã®åˆ—åã‚’ä½¿ç”¨ï¼‰
        ward_groups = df.groupby('ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', observed=True)
        
        ward_summary = pd.DataFrame({
            'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰': ward_groups['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].first(),
            'æœŸé–“æ—¥æ•°': ward_groups['æ—¥ä»˜'].nunique(),
            'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°': ward_groups[actual_columns['åœ¨é™¢æ‚£è€…æ•°']].sum(),
            'ç·å…¥é™¢æ‚£è€…æ•°': ward_groups[actual_columns['å…¥é™¢æ‚£è€…æ•°']].sum(),
            'ç·é€€é™¢æ‚£è€…æ•°': ward_groups[actual_columns['é€€é™¢æ‚£è€…æ•°']].sum(),
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ward_groups[actual_columns['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°']].sum(),
            'æ­»äº¡æ‚£è€…æ•°': ward_groups[actual_columns['æ­»äº¡æ‚£è€…æ•°']].sum()
        }).reset_index(drop=True)
        
        # è¨ˆç®—æŒ‡æ¨™ã®è¿½åŠ 
        ward_summary['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] = ward_summary['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ward_summary['æœŸé–“æ—¥æ•°']
        
        # å¹³å‡åœ¨é™¢æ—¥æ•°ã®è¨ˆç®—
        ward_summary['å¹³å‡åœ¨é™¢æ—¥æ•°'] = ward_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ((row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) / 2)
            if (row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) > 0 else 0,
            axis=1
        )
        
        # ç—…åºŠå›è»¢ç‡ã®è¨ˆç®—
        ward_summary['ç—…åºŠå›è»¢ç‡'] = ward_summary.apply(
            lambda row: row['ç·é€€é™¢æ‚£è€…æ•°'] / row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] 
            if row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        # ç·Šæ€¥å…¥é™¢ç‡ã¨æ­»äº¡ç‡
        ward_summary['ç·Šæ€¥å…¥é™¢ç‡'] = ward_summary.apply(
            lambda row: (row['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'] / row['ç·å…¥é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·å…¥é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        ward_summary['æ­»äº¡ç‡'] = ward_summary.apply(
            lambda row: (row['æ­»äº¡æ‚£è€…æ•°'] / row['ç·é€€é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·é€€é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        return ward_summary
        
    except Exception as e:
        logger.error(f"ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def calculate_department_summary(df):
    """è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—"""
    try:
        # ç—…æ£Ÿåˆ¥é›†è¨ˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
        available_columns = df.columns.tolist()
        
        column_mapping = {
            'åœ¨é™¢æ‚£è€…æ•°': ['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'åœ¨é™¢æ‚£è€…æ•°', 'ç¾åœ¨æ‚£è€…æ•°'],
            'å…¥é™¢æ‚£è€…æ•°': ['ç·å…¥é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'æ–°è¦å…¥é™¢æ‚£è€…æ•°'],
            'é€€é™¢æ‚£è€…æ•°': ['ç·é€€é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'é€€é™¢è€…æ•°'],
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ•‘æ€¥å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢'],
            'æ­»äº¡æ‚£è€…æ•°': ['æ­»äº¡æ‚£è€…æ•°', 'æ­»äº¡è€…æ•°', 'æ­»äº¡']
        }
        
        actual_columns = {}
        missing_columns = []
        
        for standard_name, possible_names in column_mapping.items():
            found_column = None
            for possible_name in possible_names:
                if possible_name in available_columns:
                    found_column = possible_name
                    break
            
            if found_column:
                actual_columns[standard_name] = found_column
            else:
                missing_columns.append(standard_name)
        
        if missing_columns:
            st.error(f"è¨ºç™‚ç§‘åˆ¥é›†è¨ˆã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
            return pd.DataFrame()
        
        # è¨ºç™‚ç§‘åˆ¥é›†è¨ˆï¼ˆå®Ÿéš›ã®åˆ—åã‚’ä½¿ç”¨ï¼‰
        dept_groups = df.groupby('è¨ºç™‚ç§‘å', observed=True)
        
        dept_summary = pd.DataFrame({
            'è¨ºç™‚ç§‘å': dept_groups['è¨ºç™‚ç§‘å'].first(),
            'æœŸé–“æ—¥æ•°': dept_groups['æ—¥ä»˜'].nunique(),
            'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°': dept_groups[actual_columns['åœ¨é™¢æ‚£è€…æ•°']].sum(),
            'ç·å…¥é™¢æ‚£è€…æ•°': dept_groups[actual_columns['å…¥é™¢æ‚£è€…æ•°']].sum(),
            'ç·é€€é™¢æ‚£è€…æ•°': dept_groups[actual_columns['é€€é™¢æ‚£è€…æ•°']].sum(),
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': dept_groups[actual_columns['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°']].sum(),
            'æ­»äº¡æ‚£è€…æ•°': dept_groups[actual_columns['æ­»äº¡æ‚£è€…æ•°']].sum()
        }).reset_index(drop=True)
        
        # è¨ˆç®—æŒ‡æ¨™ã®è¿½åŠ ï¼ˆward_summaryã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        dept_summary['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] = dept_summary['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / dept_summary['æœŸé–“æ—¥æ•°']
        
        dept_summary['å¹³å‡åœ¨é™¢æ—¥æ•°'] = dept_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ((row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) / 2)
            if (row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) > 0 else 0,
            axis=1
        )
        
        dept_summary['ç—…åºŠå›è»¢ç‡'] = dept_summary.apply(
            lambda row: row['ç·é€€é™¢æ‚£è€…æ•°'] / row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] 
            if row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        dept_summary['ç·Šæ€¥å…¥é™¢ç‡'] = dept_summary.apply(
            lambda row: (row['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'] / row['ç·å…¥é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·å…¥é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        dept_summary['æ­»äº¡ç‡'] = dept_summary.apply(
            lambda row: (row['æ­»äº¡æ‚£è€…æ•°'] / row['ç·é€€é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·é€€é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        return dept_summary
        
    except Exception as e:
        logger.error(f"è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

# ===============================================================================
# ã‚°ãƒ©ãƒ•ä½œæˆé–¢æ•°ï¼ˆæ—¢å­˜é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
# ===============================================================================

def create_ward_comparison_charts(ward_summary):
    """ç—…æ£Ÿåˆ¥æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
    try:
        st.markdown("---")
        st.subheader("ç—…æ£Ÿåˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã®æ¯”è¼ƒ
            fig_census = px.bar(
                ward_summary,
                x='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰',
                y='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                title='ç—…æ£Ÿåˆ¥ å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                color='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                color_continuous_scale='Blues'
            )
            fig_census.update_layout(height=400)
            st.plotly_chart(fig_census, use_container_width=True)
        
        with col2:
            # å¹³å‡åœ¨é™¢æ—¥æ•°ã®æ¯”è¼ƒ
            fig_alos = px.bar(
                ward_summary,
                x='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰',
                y='å¹³å‡åœ¨é™¢æ—¥æ•°',
                title='ç—…æ£Ÿåˆ¥ å¹³å‡åœ¨é™¢æ—¥æ•°',
                color='å¹³å‡åœ¨é™¢æ—¥æ•°',
                color_continuous_scale='Reds'
            )
            fig_alos.update_layout(height=400)
            st.plotly_chart(fig_alos, use_container_width=True)
        
        # æ•£å¸ƒå›³ã«ã‚ˆã‚‹ç›¸é–¢åˆ†æ
        fig_scatter = px.scatter(
            ward_summary,
            x='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
            y='å¹³å‡åœ¨é™¢æ—¥æ•°',
            size='ç·å…¥é™¢æ‚£è€…æ•°',
            hover_name='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰',
            title='å¹³å‡åœ¨é™¢æ‚£è€…æ•° vs å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·å…¥é™¢æ‚£è€…æ•°ï¼‰',
            labels={'å¹³å‡åœ¨é™¢æ‚£è€…æ•°': 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°ï¼ˆäººï¼‰', 'å¹³å‡åœ¨é™¢æ—¥æ•°': 'å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆæ—¥ï¼‰'}
        )
        fig_scatter.update_layout(height=400)
        st.plotly_chart(fig_scatter, use_container_width=True)
        
    except Exception as e:
        logger.error(f"ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

def create_department_comparison_charts(dept_summary):
    """è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
    try:
        st.markdown("---")
        st.subheader("è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã®æ¯”è¼ƒï¼ˆä¸Šä½10ä½ï¼‰
            top_census = dept_summary.nlargest(10, 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°')
            fig_census = px.bar(
                top_census,
                x='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                y='è¨ºç™‚ç§‘å',
                orientation='h',
                title='è¨ºç™‚ç§‘åˆ¥ å¹³å‡åœ¨é™¢æ‚£è€…æ•°ï¼ˆä¸Šä½10ä½ï¼‰',
                color='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                color_continuous_scale='Blues'
            )
            fig_census.update_layout(height=400)
            st.plotly_chart(fig_census, use_container_width=True)
        
        with col2:
            # å¹³å‡åœ¨é™¢æ—¥æ•°ã®æ¯”è¼ƒï¼ˆä¸Šä½10ä½ï¼‰
            top_alos = dept_summary.nlargest(10, 'å¹³å‡åœ¨é™¢æ—¥æ•°')
            fig_alos = px.bar(
                top_alos,
                x='å¹³å‡åœ¨é™¢æ—¥æ•°',
                y='è¨ºç™‚ç§‘å',
                orientation='h',
                title='è¨ºç™‚ç§‘åˆ¥ å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆä¸Šä½10ä½ï¼‰',
                color='å¹³å‡åœ¨é™¢æ—¥æ•°',
                color_continuous_scale='Reds'
            )
            fig_alos.update_layout(height=400)
            st.plotly_chart(fig_alos, use_container_width=True)
        
        # ç·Šæ€¥å…¥é™¢ç‡ã¨æ­»äº¡ç‡ã®æ•£å¸ƒå›³
        fig_rates = px.scatter(
            dept_summary,
            x='ç·Šæ€¥å…¥é™¢ç‡',
            y='æ­»äº¡ç‡',
            size='ç·å…¥é™¢æ‚£è€…æ•°',
            hover_name='è¨ºç™‚ç§‘å',
            title='ç·Šæ€¥å…¥é™¢ç‡ vs æ­»äº¡ç‡ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·å…¥é™¢æ‚£è€…æ•°ï¼‰',
            labels={'ç·Šæ€¥å…¥é™¢ç‡': 'ç·Šæ€¥å…¥é™¢ç‡ï¼ˆ%ï¼‰', 'æ­»äº¡ç‡': 'æ­»äº¡ç‡ï¼ˆ%ï¼‰'}
        )
        fig_rates.update_layout(height=400)
        st.plotly_chart(fig_rates, use_container_width=True)
        
    except Exception as e:
        logger.error(f"è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# ===============================================================================
# å‡ºåŠ›ãƒ»äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰
# ===============================================================================

def create_individual_pdf_section(df_filtered):
    """å€‹åˆ¥PDFå‡ºåŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ“„ å€‹åˆ¥PDFå‡ºåŠ›")
    
    target_data = st.session_state.get('target_data')
    
    try:
        # PDFå‡ºåŠ›è¨­å®š
        col1, col2 = st.columns(2)
        
        with col1:
            output_type = st.selectbox(
                "å‡ºåŠ›å˜ä½",
                ["å…¨ä½“", "è¨ºç™‚ç§‘åˆ¥", "ç—…æ£Ÿåˆ¥"],
                key="pdf_output_type"
            )
        
        with col2:
            pdf_orientation = st.selectbox(
                "PDFå‘ã",
                ["ç¸¦å‘ã", "æ¨ªå‘ã"],
                key="pdf_orientation"
            )
        
        # å¯¾è±¡é¸æŠ
        target_items = []
        if output_type == "è¨ºç™‚ç§‘åˆ¥":
            available_depts = sorted(df_filtered['è¨ºç™‚ç§‘å'].unique())
            target_items = st.multiselect(
                "å‡ºåŠ›å¯¾è±¡è¨ºç™‚ç§‘",
                available_depts,
                default=available_depts[:3] if len(available_depts) >= 3 else available_depts,
                key="pdf_target_depts"
            )
        elif output_type == "ç—…æ£Ÿåˆ¥":
            available_wards = sorted(df_filtered['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].unique())
            target_items = st.multiselect(
                "å‡ºåŠ›å¯¾è±¡ç—…æ£Ÿ",
                available_wards,
                default=available_wards[:3] if len(available_wards) >= 3 else available_wards,
                key="pdf_target_wards"
            )
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºæœŸé–“
        graph_days = st.slider(
            "ã‚°ãƒ©ãƒ•è¡¨ç¤ºæœŸé–“ï¼ˆæ—¥æ•°ï¼‰",
            min_value=30,
            max_value=365,
            value=90,
            step=30,
            key="pdf_graph_days"
        )
        
        # PDFç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("PDFç”Ÿæˆ", key="generate_individual_pdf"):
            if output_type != "å…¨ä½“" and not target_items:
                st.warning("å‡ºåŠ›å¯¾è±¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            else:
                generate_individual_pdfs(
                    df_filtered, target_data, output_type, target_items, 
                    pdf_orientation, graph_days
                )
    
    except Exception as e:
        logger.error(f"å€‹åˆ¥PDFå‡ºåŠ›è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"å€‹åˆ¥PDFå‡ºåŠ›è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def create_bulk_pdf_section(df_filtered):
    """ä¸€æ‹¬PDFå‡ºåŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ“š ä¸€æ‹¬PDFå‡ºåŠ›")
    
    filter_summary = get_unified_filter_summary()
    st.info(f"ğŸ“š ä¸€æ‹¬PDFå¯¾è±¡: {filter_summary}")
    st.info("ä¸€æ‹¬PDFå‡ºåŠ›æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«è©²å½“ã™ã‚‹å…¨è¨ºç™‚ç§‘ã¾ãŸã¯å…¨ç—…æ£Ÿã®PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ä¸€åº¦ã«ç”Ÿæˆã§ãã¾ã™ã€‚")

def create_prediction_analysis_section(df_filtered):
    """äºˆæ¸¬åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ”® äºˆæ¸¬åˆ†æ")
    
    if display_forecast_analysis_tab:
        try:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬åˆ†æã‚’å®Ÿè¡Œ
            original_df = st.session_state.get('df')
            st.session_state['df'] = df_filtered
            
            display_forecast_analysis_tab()
            
            st.session_state['df'] = original_df
        except Exception as e:
            logger.error(f"äºˆæ¸¬åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            st.error(f"äºˆæ¸¬åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        finally:
            if 'original_df' in locals():
                st.session_state['df'] = original_df
    else:
        st.warning("äºˆæ¸¬åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚forecast_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_prediction_analysis(df_filtered)

# ===============================================================================
# PDFç”Ÿæˆé–¢æ•°ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
# ===============================================================================

def generate_individual_pdfs(df, target_data, output_type, target_items, orientation, graph_days):
    """å€‹åˆ¥PDFç”Ÿæˆå‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    try:
        if not create_pdf:
            st.error("PDFç”Ÿæˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            return
        
        filter_summary = get_unified_filter_summary()
        st.info(f"PDFç”Ÿæˆå¯¾è±¡: {filter_summary}")
        st.info("PDFç”Ÿæˆæ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™ã€‚")
        
    except Exception as e:
        logger.error(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"PDFç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ===============================================================================
# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ç¾¤ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰
# ===============================================================================

def create_fallback_los_analysis(df_filtered, filter_config):
    """å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.info("ç°¡æ˜“ç‰ˆã®å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
    
    try:
        if df_filtered.empty:
            st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º
        filter_summary = get_unified_filter_summary()
        st.info(f"åˆ†æå¯¾è±¡: {filter_summary}")
        
        # åˆ©ç”¨å¯èƒ½ãªåˆ—åã‚’ç¢ºèª
        available_columns = df_filtered.columns.tolist()
        
        # åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        column_mapping = {
            'åœ¨é™¢æ‚£è€…æ•°': ['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'åœ¨é™¢æ‚£è€…æ•°', 'ç¾åœ¨æ‚£è€…æ•°'],
            'å…¥é™¢æ‚£è€…æ•°': ['ç·å…¥é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'æ–°è¦å…¥é™¢æ‚£è€…æ•°'],
            'é€€é™¢æ‚£è€…æ•°': ['ç·é€€é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'é€€é™¢è€…æ•°']
        }
        
        # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹åˆ—åã‚’æ±ºå®š
        actual_columns = {}
        for standard_name, possible_names in column_mapping.items():
            for possible_name in possible_names:
                if possible_name in available_columns:
                    actual_columns[standard_name] = possible_name
                    break
        
        # å¿…è¦ãªåˆ—ãŒæƒã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        required_columns = ['åœ¨é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°']
        missing_columns = [col for col in required_columns if col not in actual_columns]
        
        if missing_columns:
            st.error(f"å¹³å‡åœ¨é™¢æ—¥æ•°è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing_columns}")
            return
        
        # åŸºæœ¬çš„ãªå¹³å‡åœ¨é™¢æ—¥æ•°è¨ˆç®—
        total_patient_days = df_filtered[actual_columns['åœ¨é™¢æ‚£è€…æ•°']].sum()
        total_admissions = df_filtered[actual_columns['å…¥é™¢æ‚£è€…æ•°']].sum()
        total_discharges = df_filtered[actual_columns['é€€é™¢æ‚£è€…æ•°']].sum()
        
        if (total_admissions + total_discharges) > 0:
            alos = total_patient_days / ((total_admissions + total_discharges) / 2)
            st.metric("å¹³å‡åœ¨é™¢æ—¥æ•°", f"{alos:.2f}æ—¥")
        
        # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
        daily_alos = df_filtered.groupby('æ—¥ä»˜', observed=True).agg({
            actual_columns['åœ¨é™¢æ‚£è€…æ•°']: 'sum',
            actual_columns['å…¥é™¢æ‚£è€…æ•°']: 'sum',
            actual_columns['é€€é™¢æ‚£è€…æ•°']: 'sum'
        }).reset_index()
        
        # åˆ—åã‚’æ¨™æº–åŒ–
        daily_alos = daily_alos.rename(columns={
            actual_columns['åœ¨é™¢æ‚£è€…æ•°']: 'åœ¨é™¢æ‚£è€…æ•°',
            actual_columns['å…¥é™¢æ‚£è€…æ•°']: 'å…¥é™¢æ‚£è€…æ•°',
            actual_columns['é€€é™¢æ‚£è€…æ•°']: 'é€€é™¢æ‚£è€…æ•°'
        })
        
        daily_alos['å¹³å‡åœ¨é™¢æ—¥æ•°'] = daily_alos.apply(
            lambda row: row['åœ¨é™¢æ‚£è€…æ•°'] / ((row['å…¥é™¢æ‚£è€…æ•°'] + row['é€€é™¢æ‚£è€…æ•°']) / 2)
            if (row['å…¥é™¢æ‚£è€…æ•°'] + row['é€€é™¢æ‚£è€…æ•°']) > 0 else 0,
            axis=1
        )
        
        fig = px.line(
            daily_alos,
            x='æ—¥ä»˜',
            y='å¹³å‡åœ¨é™¢æ—¥æ•°',
            title=f'æ—¥åˆ¥å¹³å‡åœ¨é™¢æ—¥æ•°æ¨ç§»ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨æ¸ˆã¿ï¼‰'
        )
        st.plotly_chart(fig, use_container_width=True)
    
    except Exception as e:
        logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆå¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆå¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

def create_fallback_dow_analysis(df_filtered, filter_config):
    """æ›œæ—¥åˆ¥åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.info("ç°¡æ˜“ç‰ˆã®æ›œæ—¥åˆ¥åˆ†æã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
    
    try:
        if df_filtered.empty:
            st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º
        filter_summary = get_unified_filter_summary()
        st.info(f"åˆ†æå¯¾è±¡: {filter_summary}")
        
        # æ›œæ—¥ã®è¿½åŠ 
        df_copy = df_filtered.copy()
        df_copy['æ›œæ—¥'] = df_copy['æ—¥ä»˜'].dt.day_name()
        df_copy['æ›œæ—¥ç•ªå·'] = df_copy['æ—¥ä»˜'].dt.dayofweek
        
        # åˆ©ç”¨å¯èƒ½ãªåˆ—ã®ç¢ºèª
        numeric_columns = df_copy.select_dtypes(include=[np.number]).columns
        patient_columns = [col for col in numeric_columns if 'æ‚£è€…æ•°' in col]
        
        if not patient_columns:
            st.error("æ‚£è€…æ•°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æ›œæ—¥åˆ¥é›†è¨ˆ
        agg_dict = {col: 'mean' for col in patient_columns}
        dow_summary = df_copy.groupby(['æ›œæ—¥', 'æ›œæ—¥ç•ªå·'], observed=True).agg(agg_dict).reset_index()
        dow_summary = dow_summary.sort_values('æ›œæ—¥ç•ªå·')
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        fig = px.bar(
            dow_summary,
            x='æ›œæ—¥',
            y=patient_columns[:3],  # æœ€å¤§3ã¤ã¾ã§è¡¨ç¤º
            title=f'æ›œæ—¥åˆ¥å¹³å‡æ‚£è€…æ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨æ¸ˆã¿ï¼‰',
            barmode='group'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.dataframe(dow_summary, use_container_width=True)
        
    except Exception as e:
        logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆæ›œæ—¥åˆ¥åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        st.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆæ›œæ—¥åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

def create_fallback_individual_analysis(df_filtered, filter_config):
    """å€‹åˆ¥åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.info("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    filter_summary = get_unified_filter_summary()
    st.info(f"åˆ†æå¯¾è±¡: {filter_summary}")
    st.write("individual_analysis_tab.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def create_fallback_prediction_analysis(df_filtered):
    """äºˆæ¸¬åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.info("äºˆæ¸¬åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    filter_summary = get_unified_filter_summary()
    st.info(f"åˆ†æå¯¾è±¡: {filter_summary}")
    st.write("forecast_analysis_tab.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")