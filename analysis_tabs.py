import warnings
warnings.filterwarnings('ignore', category=FutureWarning, module='pandas')
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import time
import hashlib
import gc
from utils import safe_date_filter

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    # ALOSåˆ†æé–¢é€£
    from alos_analysis_tab import display_alos_analysis_tab
    
    # æ›œæ—¥åˆ¥åˆ†æé–¢é€£
    from dow_analysis_tab import display_dow_analysis_tab
    
    # å€‹åˆ¥åˆ†æé–¢é€£
    from individual_analysis_tab import display_individual_analysis_tab
    
    # äºˆæ¸¬åˆ†æé–¢é€£
    from forecast_analysis_tab import display_forecast_analysis_tab
    
    # ãƒãƒ£ãƒ¼ãƒˆä½œæˆé–¢é€£
    from chart import (
        create_interactive_patient_chart, 
        create_interactive_dual_axis_chart,
        create_forecast_comparison_chart
    )
    
    # PDFç”Ÿæˆé–¢é€£
    from pdf_generator import create_pdf, create_landscape_pdf
    
    # äºˆæ¸¬ãƒ»é›†è¨ˆé–¢é€£
    from forecast import generate_filtered_summaries, create_forecast_dataframe
    
    # KPIè¨ˆç®—é–¢é€£
    from kpi_calculator import calculate_kpis, analyze_kpi_insights
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
    from utils import get_display_name_for_dept
    
except ImportError as e:
    st.error(f"å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼é–¢æ•°ã‚’å®šç¾©
    display_alos_analysis_tab = None
    display_dow_analysis_tab = None
    display_individual_analysis_tab = None
    display_forecast_analysis_tab = None
    create_interactive_patient_chart = None
    create_interactive_dual_axis_chart = None
    create_forecast_comparison_chart = None
    create_pdf = None
    create_landscape_pdf = None
    generate_filtered_summaries = None
    create_forecast_dataframe = None
    calculate_kpis = None
    analyze_kpi_insights = None
    get_display_name_for_dept = None

# ===============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°ç¾¤
# ===============================================================================
def create_detailed_analysis_tab():
    """è©³ç´°åˆ†æã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆæœŸé–“é¸æŠåˆ†é›¢å¯¾å¿œç‰ˆï¼‰"""
    st.header("ğŸ“ˆ è©³ç´°åˆ†æ")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ã®æœŸé–“è¨­å®šã‚’å–å¾—ï¼ˆæ–°ã—ã„æ–¹å¼ï¼‰
    graph_period_type = st.session_state.get('graph_period_selector', 'ç›´è¿‘12ãƒ¶æœˆ')
    
    # ã‚°ãƒ©ãƒ•ç”¨æœŸé–“ã®è¨ˆç®—
    latest_date = df['æ—¥ä»˜'].max()
    if graph_period_type == "ç›´è¿‘12ãƒ¶æœˆ":
        graph_start_date = latest_date - pd.Timedelta(days=365)
    elif graph_period_type == "ç›´è¿‘6ãƒ¶æœˆ":
        graph_start_date = latest_date - pd.Timedelta(days=180)
    else:  # ç›´è¿‘3ãƒ¶æœˆ
        graph_start_date = latest_date - pd.Timedelta(days=90)
    
    graph_end_date = latest_date
    
    # ãƒ‡ãƒ¼ã‚¿é–‹å§‹æ—¥ã‚ˆã‚Šå‰ã«ãªã‚‰ãªã„ã‚ˆã†ã«èª¿æ•´
    actual_graph_start_date = max(graph_start_date, df['æ—¥ä»˜'].min())
    
    # æœŸé–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    df_filtered = safe_date_filter(df, actual_graph_start_date, graph_end_date)
    
    if df_filtered.empty:
        st.warning(f"é¸æŠã•ã‚ŒãŸæœŸé–“ï¼ˆ{actual_graph_start_date.date()} ï½ {graph_end_date.date()}ï¼‰ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    common_config = st.session_state.get('common_config', {})
    
    # æœŸé–“æƒ…å ±ã‚’æ˜ç¢ºã«è¡¨ç¤º
    period_days = (pd.to_datetime(graph_end_date) - pd.to_datetime(actual_graph_start_date)).days + 1
    st.info(f"ğŸ” åˆ†ææœŸé–“: {graph_period_type}ï¼ˆ{actual_graph_start_date.date()} ï½ {graph_end_date.date()}ã€{period_days}æ—¥é–“ã€{len(df_filtered):,}è¡Œã®ãƒ‡ãƒ¼ã‚¿ï¼‰")
    
    # ã‚µãƒ–ã‚¿ãƒ–ã®ä½œæˆ
    los_tab, weekday_tab, individual_tab = st.tabs([
        "ğŸ“Š å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ", 
        "ğŸ“… æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ", 
        "ğŸ” å€‹åˆ¥åˆ†æ"
    ])
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¨æœŸé–“æƒ…å ±ã‚’å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«æ¸¡ã™
    with los_tab:
        create_los_analysis_section(df_filtered, actual_graph_start_date, graph_end_date, common_config)
    
    with weekday_tab:
        create_weekday_analysis_section(df_filtered, actual_graph_start_date, graph_end_date, common_config)
    
    with individual_tab:
        # å€‹åˆ¥åˆ†æã¯ç‹¬è‡ªã®æœŸé–“é¸æŠã‚’æŒã¤å ´åˆãŒã‚ã‚‹ãŸã‚ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™
        create_individual_analysis_section(df, actual_graph_start_date, graph_end_date)

def create_data_tables_tab():
    """ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆKPIæœŸé–“å¯¾å¿œç‰ˆï¼‰"""
    st.header("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # KPIæœŸé–“è¨­å®šã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã¯çŸ­æœŸé–“ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ï¼‰
    kpi_period_type = st.session_state.get('kpi_period_selector', 'ç›´è¿‘30æ—¥')
    
    # æœŸé–“ã®è¨ˆç®—
    latest_date = df['æ—¥ä»˜'].max()
    if kpi_period_type == "ç›´è¿‘30æ—¥":
        start_date = latest_date - pd.Timedelta(days=29)
        end_date = latest_date
    elif kpi_period_type == "å‰æœˆå®Œäº†åˆ†":
        start_date = (latest_date.replace(day=1) - pd.Timedelta(days=1)).replace(day=1)
        end_date = latest_date.replace(day=1) - pd.Timedelta(days=1)
    elif kpi_period_type == "å½“æœˆå®Ÿç¸¾ï¼ˆæœˆé€”ä¸­ï¼‰":
        start_date = latest_date.replace(day=1)
        end_date = latest_date
    else:  # å½“æœˆäºˆæ¸¬
        start_date = latest_date.replace(day=1)
        end_date = latest_date
    
    df_filtered = safe_date_filter(df, start_date, end_date)
    st.info(f"ğŸ” è¡¨ç¤ºæœŸé–“: {kpi_period_type}ï¼ˆ{start_date.date()} ï½ {end_date.date()}ï¼‰")
    
    # ã‚µãƒ–ã‚¿ãƒ–ã®ä½œæˆ
    ward_table_tab, dept_table_tab = st.tabs([
        "ğŸ¥ ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«", 
        "ğŸ©º è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"
    ])
    
    with ward_table_tab:
        create_ward_table_section(df_filtered)
    
    with dept_table_tab:
        create_department_table_section(df_filtered)

def create_output_prediction_tab():
    """å‡ºåŠ›ãƒ»äºˆæ¸¬ã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆæœŸé–“é¸æŠå¯¾å¿œç‰ˆï¼‰"""
    st.header("ğŸ“„ å‡ºåŠ›ãƒ»äºˆæ¸¬")
    
    # ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    # PDFå‡ºåŠ›ç”¨ã®æœŸé–“é¸æŠUI
    st.markdown("### PDFå‡ºåŠ›æœŸé–“è¨­å®š")
    col1, col2 = st.columns(2)
    
    with col1:
        pdf_period_options = [
            "KPIæœŸé–“ã¨åŒã˜",
            "ã‚°ãƒ©ãƒ•æœŸé–“ã¨åŒã˜", 
            "ã‚«ã‚¹ã‚¿ãƒ æœŸé–“"
        ]
        pdf_period_type = st.radio(
            "PDFå‡ºåŠ›æœŸé–“",
            pdf_period_options,
            index=1,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚°ãƒ©ãƒ•æœŸé–“
            key="pdf_period_selector"
        )
    
    with col2:
        if pdf_period_type == "ã‚«ã‚¹ã‚¿ãƒ æœŸé–“":
            df_for_pdf_dates = st.session_state.get('df') # Ensure it's the original df for min/max
            if df_for_pdf_dates is not None and not df_for_pdf_dates.empty and 'æ—¥ä»˜' in df_for_pdf_dates.columns:
                min_date_dt = df_for_pdf_dates['æ—¥ä»˜'].min().date()
                max_date_dt = df_for_pdf_dates['æ—¥ä»˜'].max().date()

                # st.date_input ã® value ã¯ datetime.date ã‚’æœŸå¾…
                default_pdf_start_dt = (pd.Timestamp(max_date_dt) - pd.Timedelta(days=90)).date()
                if default_pdf_start_dt < min_date_dt: default_pdf_start_dt = min_date_dt

                pdf_start_date_input = st.date_input(
                    "é–‹å§‹æ—¥",
                    value=default_pdf_start_dt, # dateå‹
                    min_value=min_date_dt,
                    max_value=max_date_dt,
                    key="pdf_custom_start"
                )
                pdf_end_date_input = st.date_input(
                    "çµ‚äº†æ—¥",
                    value=max_date_dt, # dateå‹
                    min_value=pdf_start_date_input, # é¸æŠã•ã‚ŒãŸé–‹å§‹æ—¥ä»¥é™
                    max_value=max_date_dt,
                    key="pdf_custom_end"
                )
                # å¾Œç¶šå‡¦ç†ã®ãŸã‚ã«Timestampã«å¤‰æ›ã—ã¦ä¿æŒã™ã‚‹ãªã‚‰ã“ã“ã§
                # st.session_state.pdf_actual_start_date = pd.to_datetime(pdf_start_date_input).normalize()
                # st.session_state.pdf_actual_end_date = pd.to_datetime(pdf_end_date_input).normalize()
                # ã“ã‚Œã‚‰ã‚’å®Ÿéš›ã« safe_date_filter ã‚„ PDFç”Ÿæˆé–¢æ•°ã«æ¸¡ã™
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                # pdf_start_date = None # å¤‰æ•°åãŒè¡çªã—ãªã„ã‚ˆã†ã«
                # pdf_end_date = None
        else:
            # é¸æŠã•ã‚ŒãŸæœŸé–“ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦æœŸé–“ã‚’è¨­å®š
            if pdf_period_type == "KPIæœŸé–“ã¨åŒã˜":
                # KPIæœŸé–“ã®è¨­å®šã‚’ä½¿ç”¨
                kpi_period_type = st.session_state.get('kpi_period_selector', 'ç›´è¿‘30æ—¥')
                st.info(f"KPIæœŸé–“ï¼ˆ{kpi_period_type}ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™")
            else:  # ã‚°ãƒ©ãƒ•æœŸé–“ã¨åŒã˜
                graph_period_type = st.session_state.get('graph_period_selector', 'ç›´è¿‘12ãƒ¶æœˆ')
                st.info(f"ã‚°ãƒ©ãƒ•æœŸé–“ï¼ˆ{graph_period_type}ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    st.markdown("---")
    
    # ã‚µãƒ–ã‚¿ãƒ–ã®ä½œæˆ
    individual_pdf_tab, bulk_pdf_tab, prediction_tab = st.tabs([
        "ğŸ“„ å€‹åˆ¥PDFå‡ºåŠ›", 
        "ğŸ“š ä¸€æ‹¬PDFå‡ºåŠ›", 
        "ğŸ”® äºˆæ¸¬åˆ†æ"
    ])
    
    with individual_pdf_tab:
        create_individual_pdf_section()
    
    with bulk_pdf_tab:
        create_bulk_pdf_section()
    
    with prediction_tab:
        create_prediction_analysis_section()

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã®ä¿®æ­£ï¼ˆæœŸé–“æƒ…å ±ã‚’æ˜ç¤ºï¼‰
def create_fallback_los_analysis(df, start_date, end_date):
    """å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼ˆæœŸé–“æ˜ç¤ºç‰ˆï¼‰"""
    # æœŸé–“æƒ…å ±ã‚’æ˜ç¢ºã«è¡¨ç¤º
    period_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days + 1
    st.info(f"ç°¡æ˜“ç‰ˆã®å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚ï¼ˆ{period_days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼‰")

# ===============================================================================
# è©³ç´°åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
# ===============================================================================

def create_los_analysis_section(df_filtered, start_date, end_date, common_config):
    """å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœŸé–“å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ“Š å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ")
    
    if display_alos_analysis_tab:
        try:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¨æœŸé–“æƒ…å ±ã‚’æ¸¡ã™
            display_alos_analysis_tab(df_filtered, start_date, end_date, common_config)
            
        except Exception as e:
            st.error(f"å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚alos_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_los_analysis(df_filtered, start_date, end_date)

def create_weekday_analysis_section(df_filtered, start_date, end_date, common_config):
    """æ›œæ—¥åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœŸé–“å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ“… æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ")
    
    if display_dow_analysis_tab:
        try:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã¨æœŸé–“æƒ…å ±ã‚’æ¸¡ã™
            display_dow_analysis_tab(df_filtered, start_date, end_date, common_config)
        except Exception as e:
            st.error(f"æ›œæ—¥åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("æ›œæ—¥åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚dow_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_dow_analysis(df_filtered, start_date, end_date)

def create_individual_analysis_section(df_filtered, start_date, end_date):
    """å€‹åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœŸé–“å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ” å€‹åˆ¥åˆ†æ")
    
    if display_individual_analysis_tab:
        try:
            # å€‹åˆ¥åˆ†æç”¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä¸€æ™‚çš„ã«æ›´æ–°
            original_df = st.session_state.get('df')
            st.session_state['df'] = df_filtered  # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
            
            # å€‹åˆ¥åˆ†æå®Ÿè¡Œ
            display_individual_analysis_tab()
            
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
            st.session_state['df'] = original_df
            
        except Exception as e:
            st.error(f"å€‹åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        finally:
            # å¿µã®ãŸã‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
            if 'original_df' in locals():
                st.session_state['df'] = original_df
    else:
        st.warning("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚individual_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_individual_analysis()

# ===============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³
# ===============================================================================

def create_ward_table_section(df_filtered):
    """ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆç—…æ£Ÿåè¡¨ç¤ºå¯¾å¿œï¼‰"""
    st.subheader("ğŸ¥ ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    try:
        if df_filtered.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # ç—…æ£Ÿãƒãƒƒãƒ”ãƒ³ã‚°ã®åˆæœŸåŒ–
        from utils import initialize_all_mappings, get_ward_display_name
        initialize_all_mappings(df_filtered)
        ward_mapping = st.session_state.get('ward_mapping', {})
        
        # æœŸé–“æƒ…å ±ã®è¡¨ç¤º
        if 'æ—¥ä»˜' in df_filtered.columns:
            min_date = df_filtered['æ—¥ä»˜'].min().date()
            max_date = df_filtered['æ—¥ä»˜'].max().date()
            st.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        
        # ç—…æ£Ÿåˆ¥é›†è¨ˆ
        ward_summary = calculate_ward_summary(df_filtered)
        
        if not ward_summary.empty:
            # ç—…æ£Ÿååˆ—ã‚’è¿½åŠ 
            ward_summary['ç—…æ£Ÿå'] = ward_summary['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].apply(
                lambda x: get_ward_display_name(x, ward_mapping)
            )
            
            # åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆç—…æ£Ÿåã‚’ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã®å¾Œã«é…ç½®ï¼‰
            cols = ward_summary.columns.tolist()
            if 'ç—…æ£Ÿå' in cols:
                # ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã®å¾Œã«ç—…æ£Ÿåã‚’é…ç½®
                code_idx = cols.index('ç—…æ£Ÿã‚³ãƒ¼ãƒ‰')
                cols.insert(code_idx + 1, cols.pop(cols.index('ç—…æ£Ÿå')))
                ward_summary = ward_summary[cols]
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆç—…æ£Ÿåã‚‚å«ã‚ã¦é¸æŠå¯èƒ½ã«ï¼‰
            col1, col2 = st.columns(2)
            with col1:
                # é¸æŠè‚¢ã‚’ã€Œã‚³ãƒ¼ãƒ‰ï¼ˆåå‰ï¼‰ã€å½¢å¼ã§è¡¨ç¤º
                ward_display_options = []
                for _, row in ward_summary.iterrows():
                    code = row['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰']
                    name = row['ç—…æ£Ÿå']
                    if name != str(code):
                        display_option = f"{code}ï¼ˆ{name}ï¼‰"
                    else:
                        display_option = str(code)
                    ward_display_options.append(display_option)
                
                selected_wards = st.multiselect(
                    "è¡¨ç¤ºã™ã‚‹ç—…æ£Ÿã‚’é¸æŠï¼ˆç©ºç™½ã®å ´åˆã¯å…¨ã¦è¡¨ç¤ºï¼‰",
                    options=ward_display_options,
                    key="ward_table_filter"
                )
            
            with col2:
                sort_column = st.selectbox(
                    "ä¸¦ã³æ›¿ãˆåŸºæº–",
                    options=['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°'],
                    key="ward_table_sort"
                )
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆ
            if selected_wards:
                ward_summary = ward_summary[ward_summary['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].isin(selected_wards)]
            
            if sort_column in ward_summary.columns:
                ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã³æ›¿ãˆ", key="ward_table_ascending")
                ward_summary = ward_summary.sort_values(sort_column, ascending=ascending)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¾æ›¸ã‚’è©³ç´°ã«å®šç¾©
            format_dict = {}
            
            # å„åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã«å¿œã˜ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¨­å®š
            for col in ward_summary.columns:
                if col in ['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'é›†è¨ˆå˜ä½']:
                    # æ–‡å­—åˆ—åˆ—ã¯ãã®ã¾ã¾
                    continue
                elif col in ['æœŸé–“æ—¥æ•°', 'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 
                           'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°']:
                    # æ•´æ•°å€¤ã¨ã—ã¦è¡¨ç¤ºï¼ˆåˆè¨ˆå€¤ãƒ»ã‚«ã‚¦ãƒ³ãƒˆæ•°ï¼‰
                    format_dict[col] = "{:.0f}"
                elif col in ['å¹³å‡åœ¨é™¢æ‚£è€…æ•°']:
                    # å°æ•°ç‚¹1æ¡ã§è¡¨ç¤ºï¼ˆå¹³å‡å€¤ï¼‰
                    format_dict[col] = "{:.1f}"
                elif col in ['å¹³å‡åœ¨é™¢æ—¥æ•°', 'ç—…åºŠå›è»¢ç‡']:
                    # å°æ•°ç‚¹1æ¡ã§è¡¨ç¤ºï¼ˆæ¯”ç‡ãƒ»æ—¥æ•°ï¼‰
                    format_dict[col] = "{:.1f}"
                elif col in ['ç·Šæ€¥å…¥é™¢ç‡', 'æ­»äº¡ç‡']:
                    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã¯å°æ•°ç‚¹1æ¡ + %
                    format_dict[col] = "{:.1f}%"
                else:
                    # ãã®ä»–ã®æ•°å€¤åˆ—ã¯å°æ•°ç‚¹1æ¡
                    if pd.api.types.is_numeric_dtype(ward_summary[col]):
                        # æ•´æ•°ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                        if ward_summary[col].dtype in ['int64', 'int32', 'Int64', 'Int32']:
                            format_dict[col] = "{:.0f}"
                        else:
                            # å¹³å‡å€¤ã‹ã©ã†ã‹ã‚’åå‰ã‹ã‚‰åˆ¤å®š
                            if 'å¹³å‡' in col or 'ç‡' in col or 'æ—¥æ•°' in col:
                                format_dict[col] = "{:.1f}"
                            else:
                                format_dict[col] = "{:.0f}"
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.dataframe(
                ward_summary.style.format(format_dict),
                use_container_width=True,
                height=400
            )
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            csv_data = ward_summary.to_csv(index=False).encode('utf-8-sig')
            period_str = f"{min_date}_{max_date}" if 'æ—¥ä»˜' in df_filtered.columns else "å…¨æœŸé–“"
            st.download_button(
                label="ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f"ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿_{period_str}.csv",
                mime="text/csv"
            )
            
            # ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•
            create_ward_comparison_charts(ward_summary)
        else:
            st.warning("ç—…æ£Ÿåˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
    except Exception as e:
        st.error(f"ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ===== ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜ =====

"""
ä¿®æ­£å¾Œã®ä½¿ç”¨æ–¹æ³•:

1. utils.py ã«ç—…æ£Ÿé–¢é€£ã®é–¢æ•°ã‚’è¿½åŠ 
2. alos_analysis_tab.py ã¨ dow_analysis_tab.py ã§ utils.py ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
3. ç—…æ£Ÿé¸æŠUI ã§ã€Œ02Aï¼ˆ2éšAç—…æ£Ÿï¼‰ã€ã®ã‚ˆã†ãªè¡¨ç¤ºã«å¤‰æ›´
4. å†…éƒ¨çš„ã«ã¯ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã€è¡¨ç¤ºã®ã¿ç—…æ£Ÿåã‚’ä½¿ç”¨

ä¸»ãªå¤‰æ›´ç‚¹:
- ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ â†’ ç—…æ£Ÿåã®å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯
- é¸æŠè‚¢ã®è¡¨ç¤ºå½¢å¼ã®æ”¹å–„
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ã®ãƒãƒƒãƒ”ãƒ³ã‚°ç®¡ç†
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–

ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯åˆ†ã‹ã‚Šã‚„ã™ã„ç—…æ£Ÿåã§é¸æŠã§ãã€
ã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨ã§ã¯æ—¢å­˜ã®ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å‡¦ç†ã‚’ãã®ã¾ã¾ä½¿ç”¨ã§ãã¾ã™ã€‚
"""

def create_department_table_section(df_filtered):
    """è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"""
    st.subheader("ğŸ©º è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    try:
        if df_filtered.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æœŸé–“æƒ…å ±ã®è¡¨ç¤º
        if 'æ—¥ä»˜' in df_filtered.columns:
            min_date = df_filtered['æ—¥ä»˜'].min().date()
            max_date = df_filtered['æ—¥ä»˜'].max().date()
            st.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        
        # è¨ºç™‚ç§‘åˆ¥é›†è¨ˆ
        dept_summary = calculate_department_summary(df_filtered)
        
        if not dept_summary.empty:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            col1, col2 = st.columns(2)
            with col1:
                selected_depts = st.multiselect(
                    "è¡¨ç¤ºã™ã‚‹è¨ºç™‚ç§‘ã‚’é¸æŠï¼ˆç©ºç™½ã®å ´åˆã¯å…¨ã¦è¡¨ç¤ºï¼‰",
                    options=sorted(dept_summary['è¨ºç™‚ç§‘å'].unique()),
                    key="dept_table_filter"
                )
            
            with col2:
                sort_column = st.selectbox(
                    "ä¸¦ã³æ›¿ãˆåŸºæº–",
                    options=['è¨ºç™‚ç§‘å', 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°'],
                    key="dept_table_sort"
                )
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆ
            if selected_depts:
                dept_summary = dept_summary[dept_summary['è¨ºç™‚ç§‘å'].isin(selected_depts)]
            
            if sort_column in dept_summary.columns:
                ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã³æ›¿ãˆ", key="dept_table_ascending")
                dept_summary = dept_summary.sort_values(sort_column, ascending=ascending)
            
            # è¨ºç™‚ç§‘åã®è¡¨ç¤ºåå¤‰æ›
            if get_display_name_for_dept:
                dept_summary['è¨ºç™‚ç§‘è¡¨ç¤ºå'] = dept_summary['è¨ºç™‚ç§‘å'].apply(
                    lambda x: get_display_name_for_dept(x, x)
                )
                # è¡¨ç¤ºç”¨ã«åˆ—ã®é †åºã‚’èª¿æ•´
                cols = dept_summary.columns.tolist()
                if 'è¨ºç™‚ç§‘è¡¨ç¤ºå' in cols:
                    cols.insert(1, cols.pop(cols.index('è¨ºç™‚ç§‘è¡¨ç¤ºå')))
                    dept_summary = dept_summary[cols]
            
            # ===== ä¿®æ­£ï¼šæ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ”¹å–„ =====
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¾æ›¸ã‚’è©³ç´°ã«å®šç¾©
            format_dict = {}
            
            # å„åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã«å¿œã˜ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¨­å®š
            for col in dept_summary.columns:
                if col in ['è¨ºç™‚ç§‘å', 'è¨ºç™‚ç§‘è¡¨ç¤ºå', 'é›†è¨ˆå˜ä½']:
                    # æ–‡å­—åˆ—åˆ—ã¯ãã®ã¾ã¾
                    continue
                elif col in ['æœŸé–“æ—¥æ•°', 'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 
                           'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°']:
                    # æ•´æ•°å€¤ã¨ã—ã¦è¡¨ç¤ºï¼ˆåˆè¨ˆå€¤ãªã©ï¼‰
                    format_dict[col] = "{:.0f}"
                elif col in ['å¹³å‡åœ¨é™¢æ‚£è€…æ•°']:
                    # å°æ•°ç‚¹1æ¡ã§è¡¨ç¤ºï¼ˆå¹³å‡å€¤ï¼‰
                    format_dict[col] = "{:.1f}"
                elif col in ['å¹³å‡åœ¨é™¢æ—¥æ•°', 'ç—…åºŠå›è»¢ç‡']:
                    # å°æ•°ç‚¹1æ¡ã§è¡¨ç¤ºï¼ˆæ¯”ç‡ãƒ»æ—¥æ•°ï¼‰
                    format_dict[col] = "{:.1f}"
                elif col in ['ç·Šæ€¥å…¥é™¢ç‡', 'æ­»äº¡ç‡']:
                    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã¯å°æ•°ç‚¹1æ¡ + %
                    format_dict[col] = "{:.1f}%"
                else:
                    # ãã®ä»–ã®æ•°å€¤åˆ—ã¯å°æ•°ç‚¹1æ¡
                    if pd.api.types.is_numeric_dtype(dept_summary[col]):
                        # æ•´æ•°ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                        if dept_summary[col].dtype in ['int64', 'int32', 'Int64', 'Int32']:
                            format_dict[col] = "{:.0f}"
                        else:
                            # å¹³å‡å€¤ã‹ã©ã†ã‹ã‚’åå‰ã‹ã‚‰åˆ¤å®š
                            if 'å¹³å‡' in col or 'ç‡' in col or 'æ—¥æ•°' in col:
                                format_dict[col] = "{:.1f}"
                            else:
                                format_dict[col] = "{:.0f}"
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.dataframe(
                dept_summary.style.format(format_dict),
                use_container_width=True,
                height=400
            )
            
            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            csv_data = dept_summary.to_csv(index=False).encode('utf-8-sig')
            period_str = f"{min_date}_{max_date}" if 'æ—¥ä»˜' in df_filtered.columns else "å…¨æœŸé–“"
            st.download_button(
                label="è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f"è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿_{period_str}.csv",
                mime="text/csv"
            )
            
            # è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•
            create_department_comparison_charts(dept_summary)
        else:
            st.warning("è¨ºç™‚ç§‘åˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
    except Exception as e:
        st.error(f"è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ===============================================================================
# é›†è¨ˆå‡¦ç†é–¢æ•°
# ===============================================================================

def calculate_ward_summary(df):
    """ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—"""
    try:
        # å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—åã‚’ç¢ºèª
        available_columns = df.columns.tolist()
        
        # åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæŸ”è»Ÿãªå¯¾å¿œï¼‰
        column_mapping = {
            'åœ¨é™¢æ‚£è€…æ•°': ['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'åœ¨é™¢æ‚£è€…æ•°', 'ç¾åœ¨æ‚£è€…æ•°'],
            'å…¥é™¢æ‚£è€…æ•°': ['ç·å…¥é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'æ–°è¦å…¥é™¢æ‚£è€…æ•°'],
            'é€€é™¢æ‚£è€…æ•°': ['ç·é€€é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'é€€é™¢è€…æ•°'],
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ•‘æ€¥å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢'],
            'æ­»äº¡æ‚£è€…æ•°': ['æ­»äº¡æ‚£è€…æ•°', 'æ­»äº¡è€…æ•°', 'æ­»äº¡']
        }
        
        # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹åˆ—åã‚’æ±ºå®š
        actual_columns = {}
        missing_columns = []
        
        for standard_name, possible_names in column_mapping.items():
            found_column = None
            for possible_name in possible_names:
                if possible_name in available_columns:
                    found_column = possible_name
                    break
            
            if found_column:
                actual_columns[standard_name] = found_column
            else:
                missing_columns.append(standard_name)
        
        if missing_columns:
            st.error(f"ç—…æ£Ÿåˆ¥é›†è¨ˆã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
            return pd.DataFrame()
        
        # ç—…æ£Ÿåˆ¥é›†è¨ˆï¼ˆå®Ÿéš›ã®åˆ—åã‚’ä½¿ç”¨ï¼‰
        ward_groups = df.groupby('ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', observed=True)
        
        ward_summary = pd.DataFrame({
            'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰': ward_groups['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].first(),
            'æœŸé–“æ—¥æ•°': ward_groups['æ—¥ä»˜'].nunique(),
            'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°': ward_groups[actual_columns['åœ¨é™¢æ‚£è€…æ•°']].sum(),
            'ç·å…¥é™¢æ‚£è€…æ•°': ward_groups[actual_columns['å…¥é™¢æ‚£è€…æ•°']].sum(),
            'ç·é€€é™¢æ‚£è€…æ•°': ward_groups[actual_columns['é€€é™¢æ‚£è€…æ•°']].sum(),
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ward_groups[actual_columns['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°']].sum(),
            'æ­»äº¡æ‚£è€…æ•°': ward_groups[actual_columns['æ­»äº¡æ‚£è€…æ•°']].sum()
        }).reset_index(drop=True)
        
        # è¨ˆç®—æŒ‡æ¨™ã®è¿½åŠ 
        ward_summary['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] = ward_summary['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ward_summary['æœŸé–“æ—¥æ•°']
        
        # å¹³å‡åœ¨é™¢æ—¥æ•°ã®è¨ˆç®—
        ward_summary['å¹³å‡åœ¨é™¢æ—¥æ•°'] = ward_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ((row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) / 2)
            if (row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) > 0 else 0,
            axis=1
        )
        
        # ç—…åºŠå›è»¢ç‡ã®è¨ˆç®—
        ward_summary['ç—…åºŠå›è»¢ç‡'] = ward_summary.apply(
            lambda row: row['ç·é€€é™¢æ‚£è€…æ•°'] / row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] 
            if row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        # ç·Šæ€¥å…¥é™¢ç‡ã¨æ­»äº¡ç‡
        ward_summary['ç·Šæ€¥å…¥é™¢ç‡'] = ward_summary.apply(
            lambda row: (row['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'] / row['ç·å…¥é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·å…¥é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        ward_summary['æ­»äº¡ç‡'] = ward_summary.apply(
            lambda row: (row['æ­»äº¡æ‚£è€…æ•°'] / row['ç·é€€é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·é€€é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        return ward_summary
        
    except Exception as e:
        st.error(f"ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def calculate_department_summary(df):
    """è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—"""
    try:
        # ç—…æ£Ÿåˆ¥é›†è¨ˆã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
        available_columns = df.columns.tolist()
        
        column_mapping = {
            'åœ¨é™¢æ‚£è€…æ•°': ['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'åœ¨é™¢æ‚£è€…æ•°', 'ç¾åœ¨æ‚£è€…æ•°'],
            'å…¥é™¢æ‚£è€…æ•°': ['ç·å…¥é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'æ–°è¦å…¥é™¢æ‚£è€…æ•°'],
            'é€€é™¢æ‚£è€…æ•°': ['ç·é€€é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'é€€é™¢è€…æ•°'],
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ•‘æ€¥å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢'],
            'æ­»äº¡æ‚£è€…æ•°': ['æ­»äº¡æ‚£è€…æ•°', 'æ­»äº¡è€…æ•°', 'æ­»äº¡']
        }
        
        actual_columns = {}
        missing_columns = []
        
        for standard_name, possible_names in column_mapping.items():
            found_column = None
            for possible_name in possible_names:
                if possible_name in available_columns:
                    found_column = possible_name
                    break
            
            if found_column:
                actual_columns[standard_name] = found_column
            else:
                missing_columns.append(standard_name)
        
        if missing_columns:
            st.error(f"è¨ºç™‚ç§‘åˆ¥é›†è¨ˆã«å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")
            return pd.DataFrame()
        
        # è¨ºç™‚ç§‘åˆ¥é›†è¨ˆï¼ˆå®Ÿéš›ã®åˆ—åã‚’ä½¿ç”¨ï¼‰
        dept_groups = df.groupby('è¨ºç™‚ç§‘å', observed=True)
        
        dept_summary = pd.DataFrame({
            'è¨ºç™‚ç§‘å': dept_groups['è¨ºç™‚ç§‘å'].first(),
            'æœŸé–“æ—¥æ•°': dept_groups['æ—¥ä»˜'].nunique(),
            'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°': dept_groups[actual_columns['åœ¨é™¢æ‚£è€…æ•°']].sum(),
            'ç·å…¥é™¢æ‚£è€…æ•°': dept_groups[actual_columns['å…¥é™¢æ‚£è€…æ•°']].sum(),
            'ç·é€€é™¢æ‚£è€…æ•°': dept_groups[actual_columns['é€€é™¢æ‚£è€…æ•°']].sum(),
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': dept_groups[actual_columns['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°']].sum(),
            'æ­»äº¡æ‚£è€…æ•°': dept_groups[actual_columns['æ­»äº¡æ‚£è€…æ•°']].sum()
        }).reset_index(drop=True)
        
        # è¨ˆç®—æŒ‡æ¨™ã®è¿½åŠ ï¼ˆward_summaryã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        dept_summary['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] = dept_summary['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / dept_summary['æœŸé–“æ—¥æ•°']
        
        dept_summary['å¹³å‡åœ¨é™¢æ—¥æ•°'] = dept_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ((row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) / 2)
            if (row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) > 0 else 0,
            axis=1
        )
        
        dept_summary['ç—…åºŠå›è»¢ç‡'] = dept_summary.apply(
            lambda row: row['ç·é€€é™¢æ‚£è€…æ•°'] / row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] 
            if row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        dept_summary['ç·Šæ€¥å…¥é™¢ç‡'] = dept_summary.apply(
            lambda row: (row['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'] / row['ç·å…¥é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·å…¥é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        dept_summary['æ­»äº¡ç‡'] = dept_summary.apply(
            lambda row: (row['æ­»äº¡æ‚£è€…æ•°'] / row['ç·é€€é™¢æ‚£è€…æ•°'] * 100)
            if row['ç·é€€é™¢æ‚£è€…æ•°'] > 0 else 0,
            axis=1
        )
        
        return dept_summary
        
    except Exception as e:
        st.error(f"è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

# ===============================================================================
# ã‚°ãƒ©ãƒ•ä½œæˆé–¢æ•°
# ===============================================================================

def create_ward_comparison_charts(ward_summary):
    """ç—…æ£Ÿåˆ¥æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
    try:
        st.markdown("---")
        st.subheader("ç—…æ£Ÿåˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã®æ¯”è¼ƒ
            fig_census = px.bar(
                ward_summary,
                x='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰',
                y='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                title='ç—…æ£Ÿåˆ¥ å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                color='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                color_continuous_scale='Blues'
            )
            fig_census.update_layout(height=400)
            st.plotly_chart(fig_census, use_container_width=True)
        
        with col2:
            # å¹³å‡åœ¨é™¢æ—¥æ•°ã®æ¯”è¼ƒ
            fig_alos = px.bar(
                ward_summary,
                x='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰',
                y='å¹³å‡åœ¨é™¢æ—¥æ•°',
                title='ç—…æ£Ÿåˆ¥ å¹³å‡åœ¨é™¢æ—¥æ•°',
                color='å¹³å‡åœ¨é™¢æ—¥æ•°',
                color_continuous_scale='Reds'
            )
            fig_alos.update_layout(height=400)
            st.plotly_chart(fig_alos, use_container_width=True)
        
        # æ•£å¸ƒå›³ã«ã‚ˆã‚‹ç›¸é–¢åˆ†æ
        fig_scatter = px.scatter(
            ward_summary,
            x='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
            y='å¹³å‡åœ¨é™¢æ—¥æ•°',
            size='ç·å…¥é™¢æ‚£è€…æ•°',
            hover_name='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰',
            title='å¹³å‡åœ¨é™¢æ‚£è€…æ•° vs å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·å…¥é™¢æ‚£è€…æ•°ï¼‰',
            labels={'å¹³å‡åœ¨é™¢æ‚£è€…æ•°': 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°ï¼ˆäººï¼‰', 'å¹³å‡åœ¨é™¢æ—¥æ•°': 'å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆæ—¥ï¼‰'}
        )
        fig_scatter.update_layout(height=400)
        st.plotly_chart(fig_scatter, use_container_width=True)
        
    except Exception as e:
        st.error(f"ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

def create_department_comparison_charts(dept_summary):
    """è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®ä½œæˆ"""
    try:
        st.markdown("---")
        st.subheader("è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã®æ¯”è¼ƒï¼ˆä¸Šä½10ä½ï¼‰
            top_census = dept_summary.nlargest(10, 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°')
            fig_census = px.bar(
                top_census,
                x='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                y='è¨ºç™‚ç§‘å',
                orientation='h',
                title='è¨ºç™‚ç§‘åˆ¥ å¹³å‡åœ¨é™¢æ‚£è€…æ•°ï¼ˆä¸Šä½10ä½ï¼‰',
                color='å¹³å‡åœ¨é™¢æ‚£è€…æ•°',
                color_continuous_scale='Blues'
            )
            fig_census.update_layout(height=400)
            st.plotly_chart(fig_census, use_container_width=True)
        
        with col2:
            # å¹³å‡åœ¨é™¢æ—¥æ•°ã®æ¯”è¼ƒï¼ˆä¸Šä½10ä½ï¼‰
            top_alos = dept_summary.nlargest(10, 'å¹³å‡åœ¨é™¢æ—¥æ•°')
            fig_alos = px.bar(
                top_alos,
                x='å¹³å‡åœ¨é™¢æ—¥æ•°',
                y='è¨ºç™‚ç§‘å',
                orientation='h',
                title='è¨ºç™‚ç§‘åˆ¥ å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆä¸Šä½10ä½ï¼‰',
                color='å¹³å‡åœ¨é™¢æ—¥æ•°',
                color_continuous_scale='Reds'
            )
            fig_alos.update_layout(height=400)
            st.plotly_chart(fig_alos, use_container_width=True)
        
        # ç·Šæ€¥å…¥é™¢ç‡ã¨æ­»äº¡ç‡ã®æ•£å¸ƒå›³
        fig_rates = px.scatter(
            dept_summary,
            x='ç·Šæ€¥å…¥é™¢ç‡',
            y='æ­»äº¡ç‡',
            size='ç·å…¥é™¢æ‚£è€…æ•°',
            hover_name='è¨ºç™‚ç§‘å',
            title='ç·Šæ€¥å…¥é™¢ç‡ vs æ­»äº¡ç‡ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·å…¥é™¢æ‚£è€…æ•°ï¼‰',
            labels={'ç·Šæ€¥å…¥é™¢ç‡': 'ç·Šæ€¥å…¥é™¢ç‡ï¼ˆ%ï¼‰', 'æ­»äº¡ç‡': 'æ­»äº¡ç‡ï¼ˆ%ï¼‰'}
        )
        fig_rates.update_layout(height=400)
        st.plotly_chart(fig_rates, use_container_width=True)
        
    except Exception as e:
        st.error(f"è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# ===============================================================================
# å‡ºåŠ›ãƒ»äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³
# ===============================================================================

def create_individual_pdf_section():
    """å€‹åˆ¥PDFå‡ºåŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.subheader("ğŸ“„ å€‹åˆ¥PDFå‡ºåŠ›")
    
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    target_data = st.session_state.get('target_data')
    
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # æœŸé–“è¨­å®šã®é©ç”¨
    start_date = st.session_state.get('analysis_start_date')
    end_date = st.session_state.get('analysis_end_date')
    
    if start_date and end_date:
        df_for_pdf = safe_date_filter(df, start_date, end_date)
        st.info(f"ğŸ“„ PDFå‡ºåŠ›æœŸé–“: {start_date} ï½ {end_date}")
    else:
        df_for_pdf = df
        st.info("ğŸ“„ å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã§PDFå‡ºåŠ›")
    
    try:
        # PDFå‡ºåŠ›è¨­å®š
        col1, col2 = st.columns(2)
        
        with col1:
            output_type = st.selectbox(
                "å‡ºåŠ›å˜ä½",
                ["å…¨ä½“", "è¨ºç™‚ç§‘åˆ¥", "ç—…æ£Ÿåˆ¥"],
                key="pdf_output_type"
            )
        
        with col2:
            pdf_orientation = st.selectbox(
                "PDFå‘ã",
                ["ç¸¦å‘ã", "æ¨ªå‘ã"],
                key="pdf_orientation"
            )
        
        # å¯¾è±¡é¸æŠ
        target_items = []
        if output_type == "è¨ºç™‚ç§‘åˆ¥":
            available_depts = sorted(df_for_pdf['è¨ºç™‚ç§‘å'].unique())
            target_items = st.multiselect(
                "å‡ºåŠ›å¯¾è±¡è¨ºç™‚ç§‘",
                available_depts,
                default=available_depts[:3] if len(available_depts) >= 3 else available_depts,
                key="pdf_target_depts"
            )
        elif output_type == "ç—…æ£Ÿåˆ¥":
            available_wards = sorted(df_for_pdf['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].unique())
            target_items = st.multiselect(
                "å‡ºåŠ›å¯¾è±¡ç—…æ£Ÿ",
                available_wards,
                default=available_wards[:3] if len(available_wards) >= 3 else available_wards,
                key="pdf_target_wards"
            )
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤ºæœŸé–“
        graph_days = st.slider(
            "ã‚°ãƒ©ãƒ•è¡¨ç¤ºæœŸé–“ï¼ˆæ—¥æ•°ï¼‰",
            min_value=30,
            max_value=365,
            value=90,
            step=30,
            key="pdf_graph_days"
        )
        
        # PDFç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("PDFç”Ÿæˆ", key="generate_individual_pdf"):
            if output_type != "å…¨ä½“" and not target_items:
                st.warning("å‡ºåŠ›å¯¾è±¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            else:
                generate_individual_pdfs(
                    df_for_pdf, target_data, output_type, target_items, 
                    pdf_orientation, graph_days
                )
    
    except Exception as e:
        st.error(f"å€‹åˆ¥PDFå‡ºåŠ›è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def create_bulk_pdf_section():
    """ä¸€æ‹¬PDFå‡ºåŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.subheader("ğŸ“š ä¸€æ‹¬PDFå‡ºåŠ›")
    
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return
    
    df = st.session_state.get('df')
    target_data = st.session_state.get('target_data')
    
    if df is None or df.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # æœŸé–“è¨­å®šã®é©ç”¨
    start_date = st.session_state.get('analysis_start_date')
    end_date = st.session_state.get('analysis_end_date')
    
    if start_date and end_date:
        df_for_pdf = safe_date_filter(df, start_date, end_date)
        st.info(f"ğŸ“š ä¸€æ‹¬PDFæœŸé–“: {start_date} ï½ {end_date}")
    else:
        df_for_pdf = df
        st.info("ğŸ“š å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã§ä¸€æ‹¬PDFå‡ºåŠ›")
    
    st.info("ä¸€æ‹¬PDFå‡ºåŠ›æ©Ÿèƒ½ã«ã‚ˆã‚Šã€å…¨è¨ºç™‚ç§‘ã¾ãŸã¯å…¨ç—…æ£Ÿã®PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ä¸€åº¦ã«ç”Ÿæˆã§ãã¾ã™ã€‚")

def create_prediction_analysis_section():
    """äºˆæ¸¬åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.subheader("ğŸ”® äºˆæ¸¬åˆ†æ")
    
    if display_forecast_analysis_tab:
        try:
            display_forecast_analysis_tab()
        except Exception as e:
            st.error(f"äºˆæ¸¬åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("äºˆæ¸¬åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚forecast_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        create_fallback_prediction_analysis()

# ===============================================================================
# PDFç”Ÿæˆé–¢æ•°ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
# ===============================================================================

def generate_individual_pdfs(df, target_data, output_type, target_items, orientation, graph_days):
    """å€‹åˆ¥PDFç”Ÿæˆå‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    try:
        if not create_pdf:
            st.error("PDFç”Ÿæˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            return
        
        st.info("PDFç”Ÿæˆæ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™ã€‚")
        
    except Exception as e:
        st.error(f"PDFç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ===============================================================================
# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ç¾¤
# ===============================================================================

def create_fallback_los_analysis(df, start_date, end_date):
    """å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆ"""
    st.info("ç°¡æ˜“ç‰ˆã®å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
    
    try:
        if df.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # åˆ©ç”¨å¯èƒ½ãªåˆ—åã‚’ç¢ºèª
        available_columns = df.columns.tolist()
        
        # åˆ—åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        column_mapping = {
            'åœ¨é™¢æ‚£è€…æ•°': ['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'åœ¨é™¢æ‚£è€…æ•°', 'ç¾åœ¨æ‚£è€…æ•°'],
            'å…¥é™¢æ‚£è€…æ•°': ['ç·å…¥é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'æ–°è¦å…¥é™¢æ‚£è€…æ•°'],
            'é€€é™¢æ‚£è€…æ•°': ['ç·é€€é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'é€€é™¢è€…æ•°']
        }
        
        # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹åˆ—åã‚’æ±ºå®š
        actual_columns = {}
        for standard_name, possible_names in column_mapping.items():
            for possible_name in possible_names:
                if possible_name in available_columns:
                    actual_columns[standard_name] = possible_name
                    break
        
        # å¿…è¦ãªåˆ—ãŒæƒã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        required_columns = ['åœ¨é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°']
        missing_columns = [col for col in required_columns if col not in actual_columns]
        
        if missing_columns:
            st.error(f"å¹³å‡åœ¨é™¢æ—¥æ•°è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing_columns}")
            return
        
        # åŸºæœ¬çš„ãªå¹³å‡åœ¨é™¢æ—¥æ•°è¨ˆç®—
        total_patient_days = df[actual_columns['åœ¨é™¢æ‚£è€…æ•°']].sum()
        total_admissions = df[actual_columns['å…¥é™¢æ‚£è€…æ•°']].sum()
        total_discharges = df[actual_columns['é€€é™¢æ‚£è€…æ•°']].sum()
        
        if (total_admissions + total_discharges) > 0:
            alos = total_patient_days / ((total_admissions + total_discharges) / 2)
            st.metric("å¹³å‡åœ¨é™¢æ—¥æ•°", f"{alos:.2f}æ—¥")
        
        # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
        daily_alos = df.groupby('æ—¥ä»˜', observed=True).agg({
            actual_columns['åœ¨é™¢æ‚£è€…æ•°']: 'sum',
            actual_columns['å…¥é™¢æ‚£è€…æ•°']: 'sum',
            actual_columns['é€€é™¢æ‚£è€…æ•°']: 'sum'
        }).reset_index()
        
        # åˆ—åã‚’æ¨™æº–åŒ–
        daily_alos = daily_alos.rename(columns={
            actual_columns['åœ¨é™¢æ‚£è€…æ•°']: 'åœ¨é™¢æ‚£è€…æ•°',
            actual_columns['å…¥é™¢æ‚£è€…æ•°']: 'å…¥é™¢æ‚£è€…æ•°',
            actual_columns['é€€é™¢æ‚£è€…æ•°']: 'é€€é™¢æ‚£è€…æ•°'
        })
        
        daily_alos['å¹³å‡åœ¨é™¢æ—¥æ•°'] = daily_alos.apply(
            lambda row: row['åœ¨é™¢æ‚£è€…æ•°'] / ((row['å…¥é™¢æ‚£è€…æ•°'] + row['é€€é™¢æ‚£è€…æ•°']) / 2)
            if (row['å…¥é™¢æ‚£è€…æ•°'] + row['é€€é™¢æ‚£è€…æ•°']) > 0 else 0,
            axis=1
        )
        
        fig = px.line(
            daily_alos,
            x='æ—¥ä»˜',
            y='å¹³å‡åœ¨é™¢æ—¥æ•°',
            title=f'æ—¥åˆ¥å¹³å‡åœ¨é™¢æ—¥æ•°æ¨ç§» ({start_date} ï½ {end_date})'
        )
        st.plotly_chart(fig, use_container_width=True)
    
    except Exception as e:
        st.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆå¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

def create_fallback_dow_analysis(df, start_date, end_date):
    """æ›œæ—¥åˆ¥åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆ"""
    st.info("ç°¡æ˜“ç‰ˆã®æ›œæ—¥åˆ¥åˆ†æã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
    
    try:
        if df.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æ›œæ—¥ã®è¿½åŠ 
        df_copy = df.copy()
        df_copy['æ›œæ—¥'] = df_copy['æ—¥ä»˜'].dt.day_name()
        df_copy['æ›œæ—¥ç•ªå·'] = df_copy['æ—¥ä»˜'].dt.dayofweek
        
        # åˆ©ç”¨å¯èƒ½ãªåˆ—ã®ç¢ºèª
        numeric_columns = df_copy.select_dtypes(include=[np.number]).columns
        patient_columns = [col for col in numeric_columns if 'æ‚£è€…æ•°' in col]
        
        if not patient_columns:
            st.error("æ‚£è€…æ•°ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æ›œæ—¥åˆ¥é›†è¨ˆ
        agg_dict = {col: 'mean' for col in patient_columns}
        dow_summary = df_copy.groupby(['æ›œæ—¥', 'æ›œæ—¥ç•ªå·'], observed=True).agg(agg_dict).reset_index()
        dow_summary = dow_summary.sort_values('æ›œæ—¥ç•ªå·')
        
        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        fig = px.bar(
            dow_summary,
            x='æ›œæ—¥',
            y=patient_columns[:3],  # æœ€å¤§3ã¤ã¾ã§è¡¨ç¤º
            title=f'æ›œæ—¥åˆ¥å¹³å‡æ‚£è€…æ•° ({start_date} ï½ {end_date})',
            barmode='group'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.dataframe(dow_summary, use_container_width=True)
        
    except Exception as e:
        st.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆæ›œæ—¥åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")

def create_fallback_individual_analysis():
    """å€‹åˆ¥åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆ"""
    st.info("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    st.write("individual_analysis_tab.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def create_fallback_prediction_analysis():
    """äºˆæ¸¬åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆ"""
    st.info("äºˆæ¸¬åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    st.write("forecast_analysis_tab.pyãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")