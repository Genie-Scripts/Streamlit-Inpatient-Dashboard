# data_processing_tab.py - æ°¸ç¶šåŒ–å¯¾å¿œç‰ˆ

import streamlit as st
import pandas as pd
from datetime import datetime
import os

# æ°¸ç¶šåŒ–æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from persistent_data import (
    auto_load_persistent_data,
    save_persistent_data, 
    get_persistent_data_info,
    clear_persistent_data,
    restore_from_backup,
    export_data_info
)

# æ—¢å­˜æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from integrated_preprocessing import integrated_preprocess_data
from loader import load_files

def create_data_processing_tab():
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¿ãƒ–ï¼ˆæ°¸ç¶šåŒ–å¯¾å¿œç‰ˆï¼‰"""
    
    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‡¦ç†")
    
    # ===== ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã®è‡ªå‹•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ =====
    if not st.session_state.get('auto_load_attempted', False):
        with st.spinner("ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªä¸­..."):
            if auto_load_persistent_data():
                st.success("ğŸ’¾ å‰å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸï¼")
                st.balloons()
            st.session_state['auto_load_attempted'] = True
            st.rerun()
    
    # ===== ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã®è¡¨ç¤º =====
    display_data_status()
    
    # ===== ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ =====
    if st.session_state.get('data_processed', False):
        # ãƒ‡ãƒ¼ã‚¿ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆ
        display_data_update_section()
    else:
        # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        display_initial_upload_section()
    
    # ===== ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³ =====
    display_data_management_section()

def display_data_status():
    """ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã®è¡¨ç¤º"""
    st.markdown("### ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³")
    
    info = get_persistent_data_info()
    
    if info.get('exists') and st.session_state.get('data_processed', False):
        # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨æ™‚ã®è¡¨ç¤º
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "ãƒ‡ãƒ¼ã‚¿çŠ¶æ³",
                "âœ… èª­ã¿è¾¼ã¿æ¸ˆã¿",
                delta="ç¶™ç¶šåˆ©ç”¨å¯èƒ½"
            )
        
        with col2:
            record_count = info.get('record_count', 0)
            st.metric(
                "ãƒ‡ãƒ¼ã‚¿ä»¶æ•°", 
                f"{record_count:,}ä»¶",
                delta=info.get('date_range', 'N/A')
            )
        
        with col3:
            if 'save_timestamp' in info:
                last_update = info['save_timestamp']
                if isinstance(last_update, datetime):
                    update_str = last_update.strftime('%m/%d %H:%M')
                    days_ago = (datetime.now() - last_update).days
                    delta_str = f"{days_ago}æ—¥å‰" if days_ago > 0 else "ä»Šæ—¥"
                else:
                    update_str = "ä¸æ˜"
                    delta_str = ""
                
                st.metric(
                    "æœ€çµ‚æ›´æ–°",
                    update_str,
                    delta=delta_str
                )
        
        # è©³ç´°æƒ…å ±ã®è¡¨ç¤º
        with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿è©³ç´°æƒ…å ±", expanded=False):
            data_info = export_data_info()
            for key, value in data_info.items():
                st.write(f"**{key}**: {value}")
    
    else:
        # ãƒ‡ãƒ¼ã‚¿æœªå­˜åœ¨æ™‚ã®è¡¨ç¤º
        st.info("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸‹è¨˜ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

def display_initial_upload_section():
    """åˆå›ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown("### ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['xlsx', 'xls', 'csv'],
        accept_multiple_files=True,
        help="Excelå½¢å¼ã¾ãŸã¯CSVå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™"
    )
    
    # ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    with st.expander("ğŸ¯ ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰", expanded=False):
        target_file = st.file_uploader(
            "ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«",
            type=['xlsx', 'xls', 'csv'],
            help="ç›®æ¨™å€¤ãŒè¨­å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™"
        )
    
    # å‡¦ç†å®Ÿè¡Œ
    if uploaded_files:
        if st.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’é–‹å§‹", type="primary", use_container_width=True):
            process_and_save_data(uploaded_files, target_file)

def display_data_update_section():
    """ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    st.markdown("### ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°")
    
    with st.expander("ğŸ“ æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=False):
        st.info("ğŸ’¡ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã§ãã¾ã™ã€‚")
        
        # æ›´æ–°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        update_mode = st.radio(
            "æ›´æ–°æ–¹æ³•ã‚’é¸æŠ",
            ["å®Œå…¨ç½®æ›", "ãƒ‡ãƒ¼ã‚¿è¿½åŠ "],
            help="å®Œå…¨ç½®æ›: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ãƒ‡ãƒ¼ã‚¿ã§ç½®ãæ›ãˆ\nãƒ‡ãƒ¼ã‚¿è¿½åŠ : æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ "
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
        new_files = st.file_uploader(
            "æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['xlsx', 'xls', 'csv'],
            accept_multiple_files=True,
            key="update_files"
        )
        
        # ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
        new_target_file = st.file_uploader(
            "æ–°ã—ã„ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            type=['xlsx', 'xls', 'csv'],
            key="update_target_file"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if new_files and st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°", type="primary"):
                update_existing_data(new_files, new_target_file, update_mode)
        
        with col2:
            if st.button("ğŸ”ƒ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†å‡¦ç†"):
                reprocess_current_data()

def display_data_management_section():
    """ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
    
    if st.session_state.get('data_processed', False):
        st.markdown("### âš™ï¸ ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                export_current_data()
        
        with col2:
            if st.button("ğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ"):
                if restore_from_backup():
                    st.success("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã—ã¾ã—ãŸã€‚")
                    st.rerun()
        
        with col3:
            if st.button("ğŸ”ƒ ãƒ‡ãƒ¼ã‚¿å†èª­ã¿è¾¼ã¿"):
                reload_persistent_data()
        
        with col4:
            if st.button("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢", type="secondary"):
                show_data_clear_confirmation()

def process_and_save_data(uploaded_files, target_file=None):
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ä¿å­˜"""
    try:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­..."):
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            progress_bar = st.progress(0)
            progress_bar.progress(25, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            df_raw = load_files(None, uploaded_files)
            if df_raw is None or df_raw.empty:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return
            
            progress_bar.progress(50, "ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ä¸­...")
            
            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            df_processed, validation_results = integrated_preprocess_data(df_raw)
            if df_processed is None or df_processed.empty:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return
            
            progress_bar.progress(75, "ç›®æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")
            
            # ç›®æ¨™ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            target_data = None
            if target_file is not None:
                try:
                    target_data = load_files(None, [target_file])
                except Exception as e:
                    st.warning(f"ç›®æ¨™ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            
            progress_bar.progress(90, "ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ä¸­...")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            metadata = {
                'upload_files': [f.name for f in uploaded_files],
                'target_file': target_file.name if target_file else None,
                'validation_results': validation_results,
                'processing_timestamp': datetime.now()
            }
            
            # åŸºæœ¬è¨­å®šã®æº–å‚™
            settings = {
                'total_beds': st.session_state.get('total_beds', 612),
                'bed_occupancy_rate': st.session_state.get('bed_occupancy_rate', 0.85),
                'avg_length_of_stay': st.session_state.get('avg_length_of_stay', 12.0),
                'avg_admission_fee': st.session_state.get('avg_admission_fee', 55000)
            }
            
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            if save_persistent_data(df_processed, target_data, settings, metadata):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ›´æ–°
                st.session_state['df'] = df_processed
                st.session_state['target_data'] = target_data
                st.session_state['data_processed'] = True
                st.session_state['data_loaded_from_persistent'] = True
                
                progress_bar.progress(100, "å®Œäº†!")
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                st.balloons()
                
                # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã®è¡¨ç¤º
                show_processing_results(df_processed, validation_results)
                
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def update_existing_data(new_files, target_file, update_mode):
    """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°"""
    try:
        with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚’{update_mode}ä¸­..."):
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†
            df_new = load_files(None, new_files)
            df_new_processed, validation_results = integrated_preprocess_data(df_new)
            
            if update_mode == "å®Œå…¨ç½®æ›":
                df_final = df_new_processed
                st.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å®Œå…¨ã«ç½®ãæ›ãˆã¾ã—ãŸã€‚")
            else:  # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
                df_existing = st.session_state.get('df')
                if df_existing is not None:
                    df_final = pd.concat([df_existing, df_new_processed], ignore_index=True)
                    # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®é™¤å»
                    df_final = df_final.drop_duplicates()
                    st.info(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«{len(df_new_processed)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
                else:
                    df_final = df_new_processed
            
            # ç›®æ¨™ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            target_data = None
            if target_file is not None:
                target_data = load_files(None, [target_file])
            else:
                target_data = st.session_state.get('target_data')
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨è¨­å®šã®æº–å‚™
            metadata = {
                'update_mode': update_mode,
                'update_files': [f.name for f in new_files],
                'update_timestamp': datetime.now()
            }
            
            settings = {key: st.session_state.get(key) for key in [
                'total_beds', 'bed_occupancy_rate', 'avg_length_of_stay', 'avg_admission_fee'
            ]}
            
            # ä¿å­˜ã¨çŠ¶æ…‹æ›´æ–°
            if save_persistent_data(df_final, target_data, settings, metadata):
                st.session_state['df'] = df_final
                st.session_state['target_data'] = target_data
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                st.rerun()
                
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def reprocess_current_data():
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã®å†å‡¦ç†"""
    try:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å†å‡¦ç†ä¸­..."):
            df_current = st.session_state.get('df')
            if df_current is None:
                st.error("å†å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return
            
            # å†å‡¦ç†ï¼ˆè¨­å®šå€¤ã®å¤‰æ›´ã‚’åæ˜ ï¼‰
            settings = {key: st.session_state.get(key) for key in [
                'total_beds', 'bed_occupancy_rate', 'avg_length_of_stay', 'avg_admission_fee'
            ]}
            
            metadata = {
                'reprocess_timestamp': datetime.now(),
                'action': 'reprocess'
            }
            
            if save_persistent_data(df_current, st.session_state.get('target_data'), settings, metadata):
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã®å†å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                st.rerun()
                
    except Exception as e:
        st.error(f"å†å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def export_current_data():
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        df = st.session_state.get('df')
        if df is None:
            st.error("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv_data = df.to_csv(index=False).encode('utf-8-sig')
        
        st.download_button(
            label="ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=f"hospital_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        
        st.success("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
    except Exception as e:
        st.error(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def reload_persistent_data():
    """æ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ã®å†èª­ã¿è¾¼ã¿"""
    try:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å†èª­ã¿è¾¼ã¿ä¸­..."):
            if auto_load_persistent_data():
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸï¼")
                st.rerun()
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®å†èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                
    except Exception as e:
        st.error(f"å†èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def show_data_clear_confirmation():
    """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
    st.warning("âš ï¸ ã“ã®æ“ä½œã«ã‚ˆã‚Šã€ä¿å­˜ã•ã‚ŒãŸã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¾ã™ã€‚")
    
    if st.button("ğŸ—‘ï¸ ç¢ºèªã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤", type="secondary"):
        if clear_persistent_data():
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ã‚¯ãƒªã‚¢
            keys_to_clear = ['df', 'target_data', 'data_processed', 'data_loaded_from_persistent']
            for key in keys_to_clear:
                if key in st.session_state:
                    del st.session_state[key]
            
            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
            st.rerun()
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

def show_processing_results(df, validation_results):
    """å‡¦ç†çµæœã®è¡¨ç¤º"""
    st.markdown("### ğŸ“Š å‡¦ç†çµæœ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{len(df):,}ä»¶")
    
    with col2:
        date_range = "ä¸æ˜"
        if 'æ—¥ä»˜' in df.columns:
            min_date = df['æ—¥ä»˜'].min().strftime('%Y-%m-%d')
            max_date = df['æ—¥ä»˜'].max().strftime('%Y-%m-%d')
            date_range = f"{min_date} ï½ {max_date}"
        st.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", date_range)
    
    with col3:
        unique_wards = df['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].nunique() if 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰' in df.columns else 0
        st.metric("ç—…æ£Ÿæ•°", f"{unique_wards}ç®‡æ‰€")
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
    if validation_results:
        with st.expander("ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ", expanded=False):
            for key, value in validation_results.items():
                st.write(f"**{key}**: {value}")