import pandas as pd
import streamlit as st # Only for type hints or if st.session_state is used in main process
from io import BytesIO
import os
import re
import time
import hashlib
import gc
import numpy as np

from reportlab.lib import colors
from reportlab.lib.pagesizes import A4, landscape
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.units import mm
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT

import matplotlib.font_manager
import matplotlib.pyplot as plt
import matplotlib

# --- ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ---
FONT_DIR = 'fonts'
FONT_FILENAME = 'NotoSansJP-Regular.ttf'
FONT_PATH = os.path.join(FONT_DIR, FONT_FILENAME)
REPORTLAB_FONT_NAME = 'NotoSansJP_RL'
MATPLOTLIB_FONT_NAME_FALLBACK = 'sans-serif'
MATPLOTLIB_FONT_NAME = None # register_fonts ã§è¨­å®šã•ã‚Œã‚‹

# ğŸš€ PDFç”Ÿæˆæœ€é©åŒ–è¨­å®šã‚’è¿½åŠ 
PDF_COMPRESSION_LEVEL = 6  # åœ§ç¸®ãƒ¬ãƒ™ãƒ« (1-9)
PDF_RENDER_DPI = 120      # DPIè¨­å®š (é«˜å“è³ªã‹ã¤è»½é‡)
MATPLOTLIB_DPI = 120      # Matplotlibã®è§£åƒåº¦

# ReportLabã®æœ€é©åŒ–è¨­å®š
def optimize_pdf_settings():
    """PDFãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®æœ€é©åŒ–è¨­å®š"""
    # ReportLabã®å†…éƒ¨è¨­å®šã‚’æœ€é©åŒ–
    os.environ['REPORTLAB_OPTIMIZE'] = '1'
    
    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ”¹å–„
    try:
        import reportlab.lib.styles
        reportlab.lib.styles._baseFontName = 'Helvetica'  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æœ€é©åŒ–
    except:
        pass

# Matplotlibã®æœ€é©åŒ–è¨­å®š
def optimize_matplotlib_for_pdf():
    """Matplotlibè¨­å®šã®æœ€é©åŒ–"""
    import matplotlib
    matplotlib.use('Agg')  # GUIä¸è¦ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
    
    import matplotlib.pyplot as plt
    
    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ”¹å–„
    plt.ioff()  # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚ªãƒ•
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®æœ€é©åŒ–
    plt.rcParams.update({
        'figure.max_open_warning': 0,  # è­¦å‘Šã‚’ç„¡åŠ¹åŒ–
        'savefig.format': 'png',
        'savefig.dpi': MATPLOTLIB_DPI,
        'savefig.bbox': 'tight',
        'savefig.facecolor': 'white',
        'font.size': 8,  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’å°ã•ã
        'axes.titlesize': 10,
        'axes.labelsize': 8,
        'xtick.labelsize': 7,
        'ytick.labelsize': 7,
        'legend.fontsize': 7
    })

# ğŸš€ æœ€é©åŒ–è¨­å®šã‚’åˆæœŸåŒ–æ™‚ã«é©ç”¨
optimize_pdf_settings()
optimize_matplotlib_for_pdf()

def register_fonts():
    global MATPLOTLIB_FONT_NAME
    font_registered_rl = False
    font_registered_mpl = False

    if os.path.exists(FONT_PATH):
        try:
            pdfmetrics.registerFont(TTFont(REPORTLAB_FONT_NAME, FONT_PATH))
            print(f"ReportLab font '{REPORTLAB_FONT_NAME}' ({FONT_PATH}) registered.")
            font_registered_rl = True
        except Exception as e:
            print(f"Failed to register ReportLab font '{FONT_PATH}': {e}")

        try:
            font_entry = matplotlib.font_manager.FontEntry(
                fname=FONT_PATH, name='NotoSansJP_MPL_PDFGEN'
            )
            if font_entry.name not in [f.name for f in matplotlib.font_manager.fontManager.ttflist]:
                 matplotlib.font_manager.fontManager.ttflist.insert(0, font_entry)

            MATPLOTLIB_FONT_NAME = font_entry.name
            print(f"Matplotlib font '{MATPLOTLIB_FONT_NAME}' prepared for use from {FONT_PATH}.")
            font_registered_mpl = True
        except Exception as e:
            print(f"Failed to prepare Matplotlib font '{FONT_PATH}' for pdf_generator: {e}")
            MATPLOTLIB_FONT_NAME = None # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã¯å¾Œæ®µã«ä»»ã›ã‚‹
    else:
        print(f"Font file not found at '{FONT_PATH}'. Using fallback fonts for Matplotlib.")
        # MATPLOTLIB_FONT_NAME ã¯ã“ã®æ™‚ç‚¹ã§ã¯è¨­å®šã›ãšã€å¾Œæ®µã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã•ã›ã‚‹
    
    if not MATPLOTLIB_FONT_NAME: # Matplotlibãƒ•ã‚©ãƒ³ãƒˆãŒè¨­å®šã•ã‚Œãªã‹ã£ãŸå ´åˆ
        MATPLOTLIB_FONT_NAME = MATPLOTLIB_FONT_NAME_FALLBACK
        print(f"Using fallback Matplotlib font: {MATPLOTLIB_FONT_NAME}")


    if not font_registered_rl:
        print(f"ReportLab will use its default font or Helvetica if '{REPORTLAB_FONT_NAME}' was intended as NotoSansJP.")
    
    # ğŸš€ ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²å¾Œã«Matplotlibæœ€é©åŒ–ã‚’å†é©ç”¨
    optimize_matplotlib_for_pdf()
    
register_fonts() # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š (ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ã®ã¿ä½¿ç”¨ã•ã‚Œã‚‹æƒ³å®š) ---
def get_chart_cache():
    # Streamlitã®st.session_stateã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã¯ã€
    # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ä»¥å¤– (multiprocessingã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãªã©) ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚æ³¨æ„ãŒå¿…è¦
    # ã“ã®é–¢æ•°ã¯batch_processor.pyã®ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹å´ã§ã®ã¿ä½¿ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’æƒ³å®š
    if 'st' in globals() and hasattr(st, 'session_state'):
        if 'pdf_chart_cache' not in st.session_state:
            st.session_state.pdf_chart_cache = {}
        return st.session_state.pdf_chart_cache
    else:
        # Streamlitç’°å¢ƒå¤–ï¼ˆä¾‹: ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ï¼‰ã§å‘¼ã³å‡ºã•ã‚ŒãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        # print("Warning: get_chart_cache called outside Streamlit session_state context. Returning a dummy cache.")
        return {}


def compute_data_hash(data):
    if data is None or data.empty: return "empty_data_hash"
    try:
        return hashlib.md5(pd.util.hash_pandas_object(data, index=True).values.tobytes()).hexdigest()
    except Exception: return hashlib.md5(str(time.time()).encode()).hexdigest()

def get_chart_cache_key(title, days, target_value=None, chart_type="default", data_hash=None):
    components = [str(title), str(days)]
    if target_value is not None:
        try: components.append(f"{float(target_value):.2f}")
        except (ValueError, TypeError): components.append(str(target_value))
    else: components.append("None")
    components.append(str(chart_type))
    if data_hash: components.append(data_hash)
    key_string = "_".join(components)
    return hashlib.md5(key_string.encode()).hexdigest()


# --- ã‚°ãƒ©ãƒ•ç”Ÿæˆé–¢æ•° ---
def create_alos_chart_for_pdf(
    chart_data, title_prefix="å…¨ä½“", latest_date=None,
    moving_avg_window=30, font_name_for_mpl_to_use=None,
    days_to_show=90
):
    start_time = time.time()
    fig = None
    # ğŸš€ æœ€é©åŒ–: ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒ•ã‚©ãƒ³ãƒˆå‡¦ç†
    actual_font_name = font_name_for_mpl_to_use or MATPLOTLIB_FONT_NAME or MATPLOTLIB_FONT_NAME_FALLBACK
    font_prop = matplotlib.font_manager.FontProperties(family=actual_font_name)

    try:
        # ğŸš€ æœ€é©åŒ–: figureã‚µã‚¤ã‚ºã¨DPIã‚’æœ€é©åŒ–
        fig, ax1 = plt.subplots(figsize=(10, 5.5), dpi=MATPLOTLIB_DPI)
        
        if not isinstance(chart_data, pd.DataFrame) or chart_data.empty: 
            return None
        required_columns = ["æ—¥ä»˜", "å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰", "ç·å…¥é™¢æ‚£è€…æ•°", "ç·é€€é™¢æ‚£è€…æ•°"]
        if any(col not in chart_data.columns for col in required_columns): 
            print(f"ALOS Chart Error: Missing one or more required columns in data for {title_prefix}. Required: {required_columns}")
            return None

        # ğŸš€ æœ€é©åŒ–: ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼ã‚’æœ€å°åŒ–
        data_copy = chart_data.copy() # å¤‰æ›´ãŒåŠ ã‚ã‚‹ãŸã‚ã‚³ãƒ”ãƒ¼ã¯ç¶­æŒ
        if not pd.api.types.is_datetime64_any_dtype(data_copy['æ—¥ä»˜']):
            data_copy['æ—¥ä»˜'] = pd.to_datetime(data_copy['æ—¥ä»˜'], errors='coerce')
            data_copy.dropna(subset=['æ—¥ä»˜'], inplace=True)
        if data_copy.empty: 
            return None

        current_latest_date = latest_date if latest_date else data_copy['æ—¥ä»˜'].max()
        if pd.isna(current_latest_date): 
            current_latest_date = pd.Timestamp.now()

        start_date_limit = current_latest_date - pd.Timedelta(days=days_to_show -1)
        date_range_for_plot = pd.date_range(start=start_date_limit, end=current_latest_date, freq='D')
        
        # ğŸš€ æœ€é©åŒ–: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸè¨ˆç®—
        daily_metrics = []
        # æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        relevant_data = data_copy[(data_copy['æ—¥ä»˜'] >= date_range_for_plot.min() - pd.Timedelta(days=moving_avg_window -1)) & (data_copy['æ—¥ä»˜'] <= date_range_for_plot.max())]
        
        for display_date in date_range_for_plot:
            window_start = display_date - pd.Timedelta(days=moving_avg_window - 1)
            window_data = relevant_data[(relevant_data['æ—¥ä»˜'] >= window_start) & (relevant_data['æ—¥ä»˜'] <= display_date)]
            
            if not window_data.empty:
                total_patient_days = window_data['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰'].sum()
                total_admissions = window_data['ç·å…¥é™¢æ‚£è€…æ•°'].sum()
                total_discharges = window_data['ç·é€€é™¢æ‚£è€…æ•°'].sum()
                num_days_in_window = window_data['æ—¥ä»˜'].nunique() # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹æ—¥æ•°
                
                denominator = (total_admissions + total_discharges) / 2
                alos = total_patient_days / denominator if denominator > 0 else np.nan
                daily_census = total_patient_days / num_days_in_window if num_days_in_window > 0 else np.nan
                daily_metrics.append({'æ—¥ä»˜': display_date, 'å¹³å‡åœ¨é™¢æ—¥æ•°': alos, 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°': daily_census})

        if not daily_metrics: 
            return None
        daily_df = pd.DataFrame(daily_metrics).sort_values('æ—¥ä»˜')
        if daily_df.empty: 
            return None

        # ğŸš€ æœ€é©åŒ–: ãƒ—ãƒ­ãƒƒãƒˆå‡¦ç†ã®æœ€é©åŒ–
        ax1.plot(daily_df['æ—¥ä»˜'], daily_df['å¹³å‡åœ¨é™¢æ—¥æ•°'], color='#3498db', linewidth=2, marker='o', markersize=4, label=f"å¹³å‡åœ¨é™¢æ—¥æ•°({moving_avg_window}æ—¥MA)")
        ax1.set_xlabel('æ—¥ä»˜', fontproperties=font_prop, fontsize=10)
        ax1.set_ylabel('å¹³å‡åœ¨é™¢æ—¥æ•°', fontproperties=font_prop, fontsize=10, color='#3498db')
        ax1.tick_params(axis='y', labelcolor='#3498db', labelsize=8)
        ax1.tick_params(axis='x', labelsize=8, rotation=30)
        for label in ax1.get_xticklabels():
            label.set_fontproperties(font_prop)
            label.set_ha('right')

        ax2 = ax1.twinx()
        ax2.plot(daily_df['æ—¥ä»˜'], daily_df['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'], color='#e74c3c', linewidth=2, linestyle='--', label='å¹³å‡åœ¨é™¢æ‚£è€…æ•°')
        ax2.set_ylabel('å¹³å‡åœ¨é™¢æ‚£è€…æ•°', fontproperties=font_prop, fontsize=10, color='#e74c3c')
        ax2.tick_params(axis='y', labelcolor='#e74c3c', labelsize=8)
        # ax2ã®Xè»¸ãƒ©ãƒ™ãƒ«ã¯ax1ã¨å…±é€šãªã®ã§ã€ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã¯ä¸è¦ï¼ˆé‡è¤‡ï¼‰
        # for label in ax2.get_xticklabels(): 
        #     label.set_fontproperties(font_prop)

        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        legend_prop_obj = font_prop.copy()
        legend_prop_obj.set_size(8)
        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left', prop=legend_prop_obj)

        plt.title(f"{title_prefix} ALOSã¨åœ¨é™¢æ‚£è€…æ•°(ç›´è¿‘{days_to_show}æ—¥)", fontproperties=font_prop, fontsize=12)
        ax1.grid(True, linestyle=':', linewidth=0.5, alpha=0.7)
        plt.tight_layout(pad=0.8)
        
        # ğŸš€ æœ€é©åŒ–: é«˜å“è³ªã‹ã¤è»½é‡ãªç”»åƒå‡ºåŠ›
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=PDF_RENDER_DPI, bbox_inches='tight', facecolor='white')
        buf.seek(0)
        return buf
    except Exception as e:
        print(f"Error in create_alos_chart_for_pdf for {title_prefix}: {e}")
        import traceback; 
        print(traceback.format_exc())
        return None
    finally:
        if fig: 
            plt.close(fig)
        # ğŸš€ æœ€é©åŒ–: å¼·åˆ¶çš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()

def create_patient_chart_with_target_wrapper(
    data, title="å…¥é™¢æ‚£è€…æ•°æ¨ç§»", days=90, show_moving_average=True, target_value=None,
    font_name_for_mpl_to_use=None
):
    fig = None
    actual_font_name = font_name_for_mpl_to_use or MATPLOTLIB_FONT_NAME or MATPLOTLIB_FONT_NAME_FALLBACK
    font_prop = matplotlib.font_manager.FontProperties(family=actual_font_name)
    try:
        # ğŸš€ æœ€é©åŒ–: DPIè¨­å®šã¨ã‚µã‚¤ã‚ºæœ€é©åŒ–
        fig, ax = plt.subplots(figsize=(8, 4.0), dpi=MATPLOTLIB_DPI)
        
        if not isinstance(data, pd.DataFrame) or data.empty: 
            return None
        if "æ—¥ä»˜" not in data.columns or "å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰" not in data.columns: 
            print(f"Patient Chart Error: Missing 'æ—¥ä»˜' or 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰' in data for {title}.")
            return None

        data_copy = data.copy() # å¤‰æ›´ãŒåŠ ã‚ã‚‹ãŸã‚ã‚³ãƒ”ãƒ¼ã¯ç¶­æŒ
        if not pd.api.types.is_datetime64_any_dtype(data_copy['æ—¥ä»˜']):
            data_copy['æ—¥ä»˜'] = pd.to_datetime(data_copy['æ—¥ä»˜'], errors='coerce')
            data_copy.dropna(subset=['æ—¥ä»˜'], inplace=True)
        if data_copy.empty : 
            return None

        grouped = data_copy.groupby("æ—¥ä»˜")["å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰"].sum().reset_index().sort_values("æ—¥ä»˜")
        if len(grouped) > days: 
            grouped = grouped.tail(days)
        if grouped.empty: 
            return None

        ax.plot(grouped["æ—¥ä»˜"], grouped["å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰"], marker='o', linestyle='-', linewidth=1.5, markersize=3, color='#3498db', label='å…¥é™¢æ‚£è€…æ•°')
        avg = grouped["å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰"].mean()
        ax.axhline(y=avg, color='#e74c3c', linestyle='--', alpha=0.7, linewidth=1, label=f'å¹³å‡: {avg:.1f}')

        if show_moving_average and len(grouped) >= 7:
            grouped['7æ—¥ç§»å‹•å¹³å‡'] = grouped["å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰"].rolling(window=7, min_periods=1).mean()
            ax.plot(grouped["æ—¥ä»˜"], grouped['7æ—¥ç§»å‹•å¹³å‡'], linestyle='-', linewidth=1.2, color='#2ecc71', label='7æ—¥ç§»å‹•å¹³å‡')

        if target_value is not None and pd.notna(target_value):
            try:
                target_val_float = float(target_value)
                ax.axhline(y=target_val_float, color='#9b59b6', linestyle='-.', linewidth=1.2, label=f'ç›®æ¨™å€¤: {target_val_float:.1f}')
                caution_threshold = target_val_float * 0.97
                ax.fill_between(grouped["æ—¥ä»˜"], caution_threshold, target_val_float, color='orange', alpha=0.15, label='æ³¨æ„ã‚¾ãƒ¼ãƒ³(ç›®æ¨™æœªé”)')
            except ValueError: 
                print(f"Warning: Target value '{target_value}' for {title} not float.")

        ax.set_title(title, fontproperties=font_prop, fontsize=11)
        ax.set_xlabel('æ—¥ä»˜', fontproperties=font_prop, fontsize=9)
        ax.set_ylabel('æ‚£è€…æ•°', fontproperties=font_prop, fontsize=9)
        ax.grid(True, linestyle=':', linewidth=0.5, alpha=0.7)
        legend_font_prop = font_prop.copy(); 
        legend_font_prop.set_size(8)
        ax.legend(prop=legend_font_prop)
        ax.tick_params(axis='x', labelsize=7, rotation=30)
        for label in ax.get_xticklabels():
            label.set_fontproperties(font_prop)
            label.set_ha('right')
        ax.tick_params(axis='y', labelsize=7)
        for label in ax.get_yticklabels(): 
            label.set_fontproperties(font_prop)

        plt.tight_layout(pad=0.5)
        
        # ğŸš€ æœ€é©åŒ–: é«˜å“è³ªã‹ã¤è»½é‡ãªç”»åƒå‡ºåŠ›
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=PDF_RENDER_DPI, bbox_inches='tight', facecolor='white')
        buf.seek(0)
        return buf
    except Exception as e:
        print(f"Error in create_patient_chart_with_target_wrapper ('{title}'): {e}")
        import traceback; 
        print(traceback.format_exc())
        return None
    finally:
        if fig: 
            plt.close(fig)
        # ğŸš€ æœ€é©åŒ–: å¼·åˆ¶çš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()

def create_dual_axis_chart_for_pdf(
    data, title="æ‚£è€…ç§»å‹•ã¨åœ¨é™¢æ•°", days=90, font_name_for_mpl_to_use=None
):
    fig = None
    actual_font_name = font_name_for_mpl_to_use or MATPLOTLIB_FONT_NAME or MATPLOTLIB_FONT_NAME_FALLBACK
    font_prop = matplotlib.font_manager.FontProperties(family=actual_font_name)
    try:
        # ğŸš€ æœ€é©åŒ–: DPIè¨­å®šã¨ã‚µã‚¤ã‚ºæœ€é©åŒ–
        fig, ax1 = plt.subplots(figsize=(8, 4.0), dpi=MATPLOTLIB_DPI)
        
        if not isinstance(data, pd.DataFrame) or data.empty: 
            return None
        required_cols = ["æ—¥ä»˜", "å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰", "æ–°å…¥é™¢æ‚£è€…æ•°", "ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°", "ç·é€€é™¢æ‚£è€…æ•°"]
        if any(col not in data.columns for col in required_cols): 
            print(f"Dual Axis Chart Error: Missing one or more required columns in data for {title}. Required: {required_cols}")
            return None

        data_copy = data.copy() # å¤‰æ›´ãŒåŠ ã‚ã‚‹ãŸã‚ã‚³ãƒ”ãƒ¼ã¯ç¶­æŒ
        if not pd.api.types.is_datetime64_any_dtype(data_copy['æ—¥ä»˜']):
            data_copy['æ—¥ä»˜'] = pd.to_datetime(data_copy['æ—¥ä»˜'], errors='coerce')
            data_copy.dropna(subset=['æ—¥ä»˜'], inplace=True)
        if data_copy.empty: 
            return None

        agg_dict = {"å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰": "sum", "æ–°å…¥é™¢æ‚£è€…æ•°": "sum", "ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°": "sum", "ç·é€€é™¢æ‚£è€…æ•°": "sum"}
        grouped = data_copy.groupby("æ—¥ä»˜").agg(agg_dict).reset_index().sort_values("æ—¥ä»˜")
        if len(grouped) > days: 
            grouped = grouped.tail(days)
        if grouped.empty: 
            return None

        cols_for_ma = ["å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰", "æ–°å…¥é™¢æ‚£è€…æ•°", "ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°", "ç·é€€é™¢æ‚£è€…æ•°"]
        for col in cols_for_ma:
            if col in grouped.columns: 
                grouped[f'{col}_7æ—¥MA'] = grouped[col].rolling(window=7, min_periods=1).mean()
            else: 
                grouped[f'{col}_7æ—¥MA'] = 0 # å¿µã®ãŸã‚ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚‚MAã‚«ãƒ©ãƒ ã¯ä½œæˆ

        if "å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰_7æ—¥MA" in grouped.columns:
            ax1.plot(grouped["æ—¥ä»˜"], grouped["å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰_7æ—¥MA"], color='#3498db', linewidth=2, label="åœ¨é™¢æ‚£è€…æ•°(7æ—¥MA)")
        ax1.set_xlabel('æ—¥ä»˜', fontproperties=font_prop, fontsize=9)
        ax1.set_ylabel('åœ¨é™¢æ‚£è€…æ•°', fontproperties=font_prop, fontsize=9, color='#3498db')
        ax1.tick_params(axis='y', labelcolor='#3498db', labelsize=8)
        ax1.tick_params(axis='x', labelsize=8, rotation=30)
        for label in ax1.get_xticklabels():
            label.set_fontproperties(font_prop)
            label.set_ha('right')

        ax2 = ax1.twinx()
        colors_map = {"æ–°å…¥é™¢æ‚£è€…æ•°": "#2ecc71", "ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°": "#e74c3c", "ç·é€€é™¢æ‚£è€…æ•°": "#f39c12"}
        for col, color_val in colors_map.items():
            ma_col_name = f"{col}_7æ—¥MA"
            if ma_col_name in grouped.columns:
                ax2.plot(grouped["æ—¥ä»˜"], grouped[ma_col_name], color=color_val, linewidth=1.5, label=f"{col}(7æ—¥MA)")
        ax2.set_ylabel('æ‚£è€…ç§»å‹•æ•°', fontproperties=font_prop, fontsize=9)
        ax2.tick_params(axis='y', labelsize=8)
        for label in ax2.get_yticklabels(): 
            label.set_fontproperties(font_prop)

        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        legend_font_prop = font_prop.copy(); 
        legend_font_prop.set_size(8)
        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left', prop=legend_font_prop)

        plt.title(title, fontproperties=font_prop, fontsize=11)
        ax1.grid(True, linestyle=':', linewidth=0.5, alpha=0.7)
        plt.tight_layout(pad=0.5)
        
        # ğŸš€ æœ€é©åŒ–: é«˜å“è³ªã‹ã¤è»½é‡ãªç”»åƒå‡ºåŠ›
        buf = BytesIO()
        plt.savefig(buf, format='png', dpi=PDF_RENDER_DPI, bbox_inches='tight', facecolor='white')
        buf.seek(0)
        return buf
    except Exception as e:
        print(f"Error in create_dual_axis_chart_for_pdf ('{title}'): {e}")
        import traceback; 
        print(traceback.format_exc())
        return None
    finally:
        if fig: 
            plt.close(fig)
        # ğŸš€ æœ€é©åŒ–: å¼·åˆ¶çš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()

# --- ğŸ”§ ã‚°ãƒ©ãƒ•é‡è¤‡æ¤œè¨¼é–¢æ•°ã‚’è¿½åŠ  ---
def validate_and_deduplicate_chart_buffers(chart_buffers_dict, chart_type_name, allowed_days=None):
    """ã‚°ãƒ©ãƒ•ãƒãƒƒãƒ•ã‚¡ã®æ¤œè¨¼ã¨é‡è¤‡é™¤å»"""
    if not chart_buffers_dict:
        return {}
    
    print(f"ğŸ” VALIDATING ({chart_type_name}): Input keys: {list(chart_buffers_dict.keys())}, Allowed days: {allowed_days}") # è¿½åŠ ãƒ­ã‚°
    validated_buffers = {}
    processed_days = set()
    
    # è¨±å¯ã•ã‚ŒãŸæ—¥æ•°ã®ãƒã‚§ãƒƒã‚¯
    if allowed_days:
        allowed_days_set = set(str(d) for d in allowed_days) # æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦æ¯”è¼ƒ
    else:
        # allowed_days ãŒ None ã‚„ç©ºã®å ´åˆã¯ã€ã™ã¹ã¦ã®ãƒãƒƒãƒ•ã‚¡ã‚’è¨±å¯ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãªã„ï¼‰
        # ãŸã ã—ã€å®Ÿéš›ã«ã¯å‘¼ã³å‡ºã—å…ƒã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒè¨­å®šã•ã‚Œã‚‹æƒ³å®š
        allowed_days_set = None 
    
    for days_str_key, buffer_data in chart_buffers_dict.items():
        days_str = str(days_str_key) # ã‚­ãƒ¼ã‚’æ–‡å­—åˆ—ã¨ã—ã¦ç¢ºå®Ÿã«æ‰±ã†
        
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ (åŒã˜æ—¥æ•°ã®ã‚­ãƒ¼ãŒè¤‡æ•°å›å‡¦ç†ã•ã‚Œã‚‹ã®ã‚’é˜²ã)
        if days_str in processed_days:
            print(f"  âš ï¸ VALIDATE SKIP (Duplicate Day) ({chart_type_name}): Skipping duplicate day key '{days_str}'") # è©³ç´°ãƒ­ã‚°
            continue
        
        # è¨±å¯ã•ã‚ŒãŸæ—¥æ•°ã®ãƒã‚§ãƒƒã‚¯
        if allowed_days_set and days_str not in allowed_days_set:
            print(f"  âš ï¸ VALIDATE SKIP (Not Allowed) ({chart_type_name}): Skipping day key '{days_str}' (Not in {allowed_days_set})") # è©³ç´°ãƒ­ã‚°
            continue
        
        # ãƒãƒƒãƒ•ã‚¡ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
        if buffer_data and (isinstance(buffer_data, bytes) or hasattr(buffer_data, 'getvalue')):
            validated_buffers[days_str] = buffer_data # æœ‰åŠ¹ãªãƒãƒƒãƒ•ã‚¡ã‚’æ–‡å­—åˆ—ã‚­ãƒ¼ã§ä¿å­˜
            processed_days.add(days_str)
            buffer_length = 'N/A'
            if isinstance(buffer_data, bytes):
                buffer_length = len(buffer_data)
            elif hasattr(buffer_data, 'getvalue'):
                try:
                    # BytesIOã®å ´åˆã€getvalue()ã§å†…å®¹ã‚’å–å¾—ã—é•·ã•ã‚’ç¢ºèª
                    buffer_length = len(buffer_data.getvalue())
                except Exception:
                    pass # getvalue() ãŒå¤±æ•—ã™ã‚‹å ´åˆãªã©ï¼ˆé€šå¸¸ã¯ãªã„ã¯ãšï¼‰
            print(f"  âœ… VALIDATE OK ({chart_type_name}): Added buffer for day '{days_str}' (Size: {buffer_length})") # è©³ç´°ãƒ­ã‚°
        else:
            print(f"  âŒ VALIDATE FAIL (Invalid Buffer) ({chart_type_name}): Invalid buffer for day '{days_str}' (Type: {type(buffer_data)})") # è©³ç´°ãƒ­ã‚°
    
    print(f"ğŸ VALIDATED ({chart_type_name}): Output keys: {list(validated_buffers.keys())}") # è¿½åŠ ãƒ­ã‚°
    return validated_buffers

# Example usage (for context, not part of the function itself):
if __name__ == '__main__':
    # Dummy buffer data
    dummy_buffer_90 = BytesIO(b"graph_data_90_days").getvalue() # Simulating bytes
    dummy_buffer_180 = BytesIO(b"graph_data_180_days_longer").getvalue()
    dummy_buffer_30_invalid = None
    dummy_buffer_90_duplicate = BytesIO(b"graph_data_90_days_duplicate").getvalue()


    print("--- Test Case 1: Basic 90 and 180 days ---")
    test_buffers1 = {'90': dummy_buffer_90, '180': dummy_buffer_180}
    allowed1 = ['90', '180']
    validate_and_deduplicate_chart_buffers(test_buffers1, "ALOS_Test1", allowed1)
    # Expected: Both 90 and 180 should be validated.

    print("\n--- Test Case 2: Only 90 days allowed ---")
    allowed2 = ['90']
    validate_and_deduplicate_chart_buffers(test_buffers1, "ALOS_Test2", allowed2)
    # Expected: Only 90 should be validated, 180 skipped.

    print("\n--- Test Case 3: Invalid buffer and not allowed day ---")
    test_buffers3 = {'90': dummy_buffer_90, '30': dummy_buffer_30_invalid, '180': dummy_buffer_180}
    allowed3 = ['90', '180']
    validate_and_deduplicate_chart_buffers(test_buffers3, "Patient_Test3", allowed3)
    # Expected: 90 and 180 validated, 30 skipped (invalid buffer).

    print("\n--- Test Case 4: Duplicate day key (though dicts inherently handle this by overwrite) ---")
    # Python dicts don't allow true duplicate keys in literal, last one wins.
    # This part of the function's logic (if days_str in processed_days:) is more for
    # scenarios where keys might be generated in a loop and could accidentally repeat.
    test_buffers4 = {}
    test_buffers4['90'] = dummy_buffer_90
    # If there was a way to force {'90':val1, '90':val2}, the logic would be tested.
    # Instead, we simulate chart_buffers_dict being built in a way that might lead to this,
    # but practically, the processed_days check ensures each unique day string is added once.
    print("Simulating a scenario where '90' might appear multiple times before this function if keys were not unique.")
    # This test case isn't perfect for dicts, but shows the processed_days logic.
    # A more realistic test would be to call it with a dict that already has a key, then another call.
    
    print("\n--- Test Case 5: Integer keys in input dict ---")
    test_buffers5 = {90: dummy_buffer_90, 180: dummy_buffer_180, '30': dummy_buffer_90} # Mix of int and str keys
    allowed5 = ['90', '180'] # Allowed days are strings
    validate_and_deduplicate_chart_buffers(test_buffers5, "DualAxis_Test5", allowed5)
    # Expected: 90 and 180 (from int keys) should be validated and converted to string keys. '30' also validated.

# --- PDFç”Ÿæˆãƒ¡ã‚¤ãƒ³é–¢æ•° ---
def create_pdf(
    forecast_df, df_weekday, df_holiday, df_all_avg=None,
    chart_data=None, title_prefix="å…¨ä½“", latest_date=None,
    target_data=None, filter_code="å…¨ä½“", graph_days=None, # graph_days ã¯å¤ã„å¼•æ•°åã€allowed_graph_days ã‚’å„ªå…ˆ
    alos_chart_buffers=None,
    patient_chart_buffers=None,
    dual_axis_chart_buffers=None,
    allowed_graph_days=None  # ğŸ”§ ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ­£ã—ãä½¿ç”¨ã™ã‚‹
):
    pdf_start_time = time.time()
    elements = []
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4,
                            leftMargin=15*mm, rightMargin=15*mm,
                            topMargin=18*mm, bottomMargin=18*mm)

    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name='Normal_JP', parent=styles['Normal'], fontName=REPORTLAB_FONT_NAME, fontSize=8, leading=10))
    styles.add(ParagraphStyle(name='Heading1_JP', parent=styles['Heading1'], fontName=REPORTLAB_FONT_NAME, fontSize=14, spaceAfter=5*mm, leading=16))
    styles.add(ParagraphStyle(name='Heading2_JP', parent=styles['Heading2'], fontName=REPORTLAB_FONT_NAME, fontSize=11, spaceAfter=3*mm, leading=14))
    styles.add(ParagraphStyle(name='Normal_Center_JP', parent=styles['Normal_JP'], alignment=TA_CENTER, fontSize=7, leading=8))

    normal_ja = styles['Normal_JP']
    ja_style = styles['Heading1_JP']
    ja_heading2 = styles['Heading2_JP']
    para_style_normal_center = styles['Normal_Center_JP']

    current_latest_date = latest_date if latest_date else pd.Timestamp.now().normalize()
    if isinstance(current_latest_date, str): current_latest_date = pd.Timestamp(current_latest_date)
    data_date_str = current_latest_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
    today_str = pd.Timestamp.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

    report_title_text = f"å…¥é™¢æ‚£è€…æ•°äºˆæ¸¬ - {title_prefix}ï¼ˆãƒ‡ãƒ¼ã‚¿åŸºæº–æ—¥: {data_date_str}ï¼‰"
    elements.append(Paragraph(report_title_text, ja_style))
    elements.append(Spacer(1, 5*mm))
    page_width = A4[0] - doc.leftMargin - doc.rightMargin
    graphs_on_current_page = 0
    max_graphs_per_page = 2 # 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®æœ€å¤§ã‚°ãƒ©ãƒ•æ•°

    # ğŸ”§ è¨±å¯ã•ã‚ŒãŸæ—¥æ•°ã®è¨­å®šã‚’ä¿®æ­£
    if not allowed_graph_days: # None ã¾ãŸã¯ç©ºã®ãƒªã‚¹ãƒˆã®å ´åˆ
        current_allowed_graph_days = ["90"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Fast Modeç›¸å½“
        print(f"âš ï¸ PDFç”Ÿæˆ ({title_prefix}): allowed_graph_days ãŒæŒ‡å®šã•ã‚Œãªã‹ã£ãŸã‹ç©ºã®ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® ['90'] æ—¥ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    else:
        current_allowed_graph_days = [str(d) for d in allowed_graph_days] # æ–‡å­—åˆ—ã«å¤‰æ›
    
    print(f"ğŸ”§ PDFç”Ÿæˆ ({title_prefix}): create_pdf é–¢æ•°ãŒä½¿ç”¨ã™ã‚‹ã‚°ãƒ©ãƒ•æ—¥æ•°: {current_allowed_graph_days}")
    
    # ğŸ”§ ã‚°ãƒ©ãƒ•ãƒãƒƒãƒ•ã‚¡ã®æ¤œè¨¼ã¨é‡è¤‡é™¤å» (ä¿®æ­£ã•ã‚ŒãŸ current_allowed_graph_days ã‚’ä½¿ç”¨)
    validated_alos_buffers = validate_and_deduplicate_chart_buffers(
        alos_chart_buffers, "ALOSã‚°ãƒ©ãƒ•", current_allowed_graph_days
    ) if alos_chart_buffers else {}
    
    validated_patient_buffers = {}
    if patient_chart_buffers:
        for chart_type, buffers in patient_chart_buffers.items():
            validated_patient_buffers[chart_type] = validate_and_deduplicate_chart_buffers(
                buffers, f"æ‚£è€…æ•°æ¨ç§»ã‚°ãƒ©ãƒ•({chart_type})", current_allowed_graph_days
            )
    
    validated_dual_axis_buffers = validate_and_deduplicate_chart_buffers(
        dual_axis_chart_buffers, "äºŒè»¸ã‚°ãƒ©ãƒ•", current_allowed_graph_days
    ) if dual_axis_chart_buffers else {}

    # ğŸ”§ æ¤œè¨¼æ¸ˆã¿ãƒãƒƒãƒ•ã‚¡ã®å†…å®¹ç¢ºèª (ãƒ‡ãƒãƒƒã‚°ç”¨)
    # print(f"ğŸ”§ æ¤œè¨¼æ¸ˆã¿ALOSãƒãƒƒãƒ•ã‚¡ ({title_prefix}): {list(validated_alos_buffers.keys())}")
    # for chart_type, buffers in validated_patient_buffers.items():
    #     if buffers: print(f"ğŸ”§ æ¤œè¨¼æ¸ˆã¿æ‚£è€…æ•°æ¨ç§»ãƒãƒƒãƒ•ã‚¡({chart_type}, {title_prefix}): {list(buffers.keys())}")
    # print(f"ğŸ”§ æ¤œè¨¼æ¸ˆã¿äºŒè»¸ãƒãƒƒãƒ•ã‚¡ ({title_prefix}): {list(validated_dual_axis_buffers.keys())}")

    # ã‚°ãƒ©ãƒ•è¿½åŠ å‡¦ç† (ALOS, æ‚£è€…æ•°æ¨ç§», äºŒè»¸)
    # ã‚°ãƒ©ãƒ•ã®ç¨®é¡ã”ã¨ã«è¿½åŠ ã—ã€ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šã‚’é©åˆ‡ã«ç®¡ç†
    
    all_graph_types_to_process = []
    if validated_alos_buffers:
        all_graph_types_to_process.append(
            ("ALOS", validated_alos_buffers, f"å¹³å‡åœ¨é™¢æ—¥æ•°ã¨å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã®æ¨ç§»ï¼ˆç›´è¿‘%sæ—¥é–“ï¼‰")
        )
    if validated_patient_buffers:
        type_name_map = {"all": "å…¨æ—¥", "weekday": "å¹³æ—¥", "holiday": "ä¼‘æ—¥"}
        for chart_type_key in ["all", "weekday", "holiday"]: # è¡¨ç¤ºé †ã‚’å›ºå®š
            day_buffers_dict = validated_patient_buffers.get(chart_type_key, {})
            if day_buffers_dict:
                display_name = type_name_map.get(chart_type_key, chart_type_key.capitalize())
                all_graph_types_to_process.append(
                    (f"æ‚£è€…æ•°æ¨ç§»_{chart_type_key}", day_buffers_dict, f"{display_name} å…¥é™¢æ‚£è€…æ•°æ¨ç§»ï¼ˆç›´è¿‘%sæ—¥é–“ï¼‰")
                )
    if validated_dual_axis_buffers:
        all_graph_types_to_process.append(
            ("äºŒè»¸", validated_dual_axis_buffers, f"æ‚£è€…ç§»å‹•ã¨åœ¨é™¢æ•°ã®æ¨ç§»ï¼ˆç›´è¿‘%sæ—¥é–“ï¼‰")
        )

    # ã‚°ãƒ©ãƒ•æç”»ãƒ«ãƒ¼ãƒ—
    for graph_name, buffers_dict, title_template in all_graph_types_to_process:
        print(f"ğŸ“„ ADDING GRAPHS TO PDF ({title_prefix}): Processing graph type '{graph_name}'")
        print(f"  Buffers_dict for '{graph_name}': Keys = {list(buffers_dict.keys())}")
        
        try:
            valid_items_for_sorting = []
            for k, v_buf in buffers_dict.items():
                try:
                    int(k) 
                    valid_items_for_sorting.append((k,v_buf))
                except ValueError:
                    print(f"  âš ï¸ SORTING WARNING ({title_prefix}, {graph_name}): Key '{k}' cannot be converted to int, skipping for sort.")
            
            if not valid_items_for_sorting:
                print(f"  âš ï¸ NO VALID ITEMS FOR SORTING ({title_prefix}, {graph_name})")
                continue

            sorted_buffer_items = sorted(valid_items_for_sorting, key=lambda item: int(item[0]))
            print(f"  Sorted items for '{graph_name}': {[item[0] for item in sorted_buffer_items]}")
        except Exception as e_sort:
            print(f"  âŒ SORTING ERROR ({title_prefix}, {graph_name}): {e_sort}. Original keys: {list(buffers_dict.keys())}")
            continue

        for days_val_str, chart_buffer_bytes in sorted_buffer_items:
            print(f"    Attempting to add '{graph_name}' for '{days_val_str}' days.")
            if graphs_on_current_page >= max_graphs_per_page:
                elements.append(PageBreak())
                elements.append(Paragraph(report_title_text, ja_style))
                elements.append(Spacer(1, 5*mm))
                graphs_on_current_page = 0
                
            if chart_buffer_bytes:
                try:
                    if isinstance(chart_buffer_bytes, bytes):
                        img_buf = BytesIO(chart_buffer_bytes)
                    elif hasattr(chart_buffer_bytes, 'getvalue'): 
                        img_buf = chart_buffer_bytes 
                    else:
                        print(f"    âŒ SKIPPING '{graph_name}' ('{days_val_str}' days): Invalid buffer type {type(chart_buffer_bytes)}")
                        continue
                    
                    img_buf.seek(0) # BytesIOã®ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«
                    
                    # === ã“ã“ã‹ã‚‰ãƒ‡ãƒãƒƒã‚°ç”¨: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ ===
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã«PIDã‚’è¿½åŠ ã—ã¦ã€ä¸¦åˆ—å‡¦ç†ã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸Šæ›¸ãã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
                    pid_for_filename = os.getpid() 
                    safe_title_prefix = "".join(c if c.isalnum() else '_' for c in title_prefix) # ãƒ•ã‚¡ã‚¤ãƒ«åå®‰å…¨åŒ–
                    debug_image_filename = f"debug_pid{pid_for_filename}_{safe_title_prefix}_{graph_name.replace('/', '_')}_{days_val_str}.png"
                    try:
                        with open(debug_image_filename, "wb") as f_debug_img:
                            f_debug_img.write(img_buf.getvalue()) # getvalue()ã§å…¨ãƒã‚¤ãƒˆå–å¾—
                        print(f"    ğŸ–¼ï¸ DEBUG IMAGE SAVED: {debug_image_filename}")
                    except Exception as e_debug_save:
                        print(f"    âš ï¸ DEBUG IMAGE SAVE FAILED for {debug_image_filename}: {e_debug_save}")
                    img_buf.seek(0) # ä¿å­˜å¾Œã€å†åº¦ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™ (Imageã§ä½¿ã‚ã‚Œã‚‹ãŸã‚)
                    # === ãƒ‡ãƒãƒƒã‚°ç”¨ã“ã“ã¾ã§ ===

                    elements.append(Paragraph(title_template % days_val_str, ja_heading2))
                    elements.append(Spacer(1, 1.5*mm))
                    elements.append(Image(img_buf, width=page_width*0.9, height=(page_width*0.9)*0.45))
                    elements.append(Spacer(1, 3*mm))
                    graphs_on_current_page += 1
                    print(f"    âœ… Added '{graph_name}' for '{days_val_str}' days successfully.")
                except Exception as e:
                    print(f"    âŒ ERROR adding '{graph_name}' for '{days_val_str}' days to PDF: {e}")
                    import traceback
                    print(traceback.format_exc()) # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’å‡ºåŠ›
            else:
                print(f"    â„¹ï¸ SKIPPING '{graph_name}' ('{days_val_str}' days): Buffer is empty/None.")
        
        # æœ€å¾Œã®ã‚°ãƒ©ãƒ•ã‚»ãƒƒãƒˆã®å¾Œã§ã€æ¬¡ã®è¦ç´ ãŒãƒ†ãƒ¼ãƒ–ãƒ«ãªã‚‰ãƒšãƒ¼ã‚¸ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚’å…¥ã‚Œã‚‹åˆ¤æ–­ã‚’æ”¹å–„
        if graphs_on_current_page > 0 and graph_name != all_graph_types_to_process[-1][0] : # æœ€å¾Œã®ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã§ãªã‘ã‚Œã°
             if graphs_on_current_page >= max_graphs_per_page : # ãƒšãƒ¼ã‚¸ãŒåŸ‹ã¾ã£ã¦ã„ãŸã‚‰æ”¹ãƒšãƒ¼ã‚¸
                 pass # ãƒ«ãƒ¼ãƒ—ã®å…ˆé ­ã§æ”¹ãƒšãƒ¼ã‚¸ã•ã‚Œã‚‹
             elif graphs_on_current_page > 0 : # ãƒšãƒ¼ã‚¸ã«ã‚°ãƒ©ãƒ•ãŒæ®‹ã£ã¦ã„ã¦ã€æ¬¡ã®ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã«ç§»ã‚‹ãªã‚‰
                 elements.append(PageBreak())
                 elements.append(Paragraph(report_title_text, ja_style))
                 elements.append(Spacer(1, 5*mm))
                 graphs_on_current_page = 0


    # ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®å‰ã«ã€ã‚°ãƒ©ãƒ•ã§ãƒšãƒ¼ã‚¸ãŒé€”ä¸­ãªã‚‰æ”¹ãƒšãƒ¼ã‚¸
    if graphs_on_current_page > 0:
        elements.append(PageBreak())
        elements.append(Paragraph(report_title_text, ja_style)) # æ–°ã—ã„ãƒšãƒ¼ã‚¸ã«ã‚‚ã‚¿ã‚¤ãƒˆãƒ«
        elements.append(Spacer(1, 5*mm))
        # graphs_on_current_page = 0 # ãƒ†ãƒ¼ãƒ–ãƒ«ã¯åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ

    common_table_style_cmds = [
        ('FONTNAME', (0,0), (-1,-1), REPORTLAB_FONT_NAME), ('GRID', (0,0), (-1,-1), 0.5, colors.black),
        ('VALIGN', (0,0), (-1,-1), 'MIDDLE'), ('ALIGN', (0,0), (-1,0), 'CENTER'), 
        ('ALIGN', (1,1), (-1,-1), 'RIGHT'), ('ALIGN', (0,1), (0,-1), 'LEFT'),   
        ('FONTSIZE', (0,0), (-1,0), 9), ('FONTSIZE', (0,1), (-1,-1), 8),   
        ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke), ('LEFTPADDING', (0,0), (-1,-1), 2*mm), 
        ('RIGHTPADDING', (0,0), (-1,-1), 2*mm),
    ]
    if df_all_avg is not None and not df_all_avg.empty:
        elements.append(Paragraph("å…¨æ—¥å¹³å‡å€¤ï¼ˆå¹³æ—¥ãƒ»ä¼‘æ—¥å«ã‚€ï¼‰", ja_heading2))
        header = [df_all_avg.index.name if df_all_avg.index.name else "åŒºåˆ†"] + df_all_avg.columns.tolist()
        table_data = [header] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in df_all_avg.iterrows()]
        num_cols = len(header); col_widths = [page_width*0.2] + [(page_width*0.8)/(num_cols-1 if num_cols > 1 else 1)]*(num_cols-1)
        elements.append(Table(table_data, colWidths=col_widths, style=TableStyle(common_table_style_cmds + [('BACKGROUND', (0,0), (-1,0), colors.green)])))
        elements.append(Spacer(1, 4*mm))

    if forecast_df is not None and not forecast_df.empty:
        elements.append(Paragraph("åœ¨é™¢æ‚£è€…æ•°äºˆæ¸¬", ja_heading2))
        fc_df_mod = forecast_df.copy()
        if "å¹´é–“å¹³å‡äººæ—¥ï¼ˆå®Ÿç¸¾ï¼‹äºˆæ¸¬ï¼‰" in fc_df_mod.columns: fc_df_mod.rename(columns={"å¹´é–“å¹³å‡äººæ—¥ï¼ˆå®Ÿç¸¾ï¼‹äºˆæ¸¬ï¼‰": "å¹´åº¦äºˆæ¸¬"}, inplace=True)
        if "å»¶ã¹äºˆæ¸¬äººæ—¥" in fc_df_mod.columns: fc_df_mod.drop(columns=["å»¶ã¹äºˆæ¸¬äººæ—¥"], inplace=True)
        header = [fc_df_mod.index.name if fc_df_mod.index.name else "åŸºæº–"] + fc_df_mod.columns.tolist()
        table_data = [header] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in fc_df_mod.iterrows()]
        num_cols = len(header); col_widths_fc = [page_width*0.25] + [(page_width*0.75)/(num_cols-1 if num_cols > 1 else 1)]*(num_cols-1)
        elements.append(Table(table_data, colWidths=col_widths_fc, style=TableStyle(common_table_style_cmds + [('BACKGROUND', (0,0), (-1,0), colors.blue)])))
        elements.append(Spacer(1, 4*mm))
    
    # å¹³æ—¥ãƒ»ä¼‘æ—¥ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‰ã«æ”¹ãƒšãƒ¼ã‚¸
    if (df_weekday is not None and not df_weekday.empty) or \
       (df_holiday is not None and not df_holiday.empty):
        elements.append(PageBreak())
        elements.append(Paragraph(report_title_text, ja_style))
        elements.append(Spacer(1, 5*mm))

    if df_weekday is not None and not df_weekday.empty:
        elements.append(Paragraph("å¹³æ—¥å¹³å‡å€¤", ja_heading2))
        header = [df_weekday.index.name if df_weekday.index.name else "åŒºåˆ†"] + df_weekday.columns.tolist()
        table_data = [header] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in df_weekday.iterrows()]
        num_cols = len(header); col_widths = [page_width*0.2] + [(page_width*0.8)/(num_cols-1 if num_cols > 1 else 1)]*(num_cols-1)
        elements.append(Table(table_data, colWidths=col_widths, style=TableStyle(common_table_style_cmds + [('BACKGROUND', (0,0), (-1,0), colors.teal)])))
        elements.append(Spacer(1, 4*mm))
    if df_holiday is not None and not df_holiday.empty:
        elements.append(Paragraph("ä¼‘æ—¥å¹³å‡å€¤", ja_heading2))
        header = [df_holiday.index.name if df_holiday.index.name else "åŒºåˆ†"] + df_holiday.columns.tolist()
        table_data = [header] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in df_holiday.iterrows()]
        num_cols = len(header); col_widths = [page_width*0.2] + [(page_width*0.8)/(num_cols-1 if num_cols > 1 else 1)]*(num_cols-1)
        elements.append(Table(table_data, colWidths=col_widths, style=TableStyle(common_table_style_cmds + [('BACKGROUND', (0,0), (-1,0), colors.orange)])))
        elements.append(Spacer(1, 4*mm))

    if chart_data is not None and not chart_data.empty:
        generated_ward_table_data, generated_dept_table_data, period_labels_dept_ward = create_department_tables(
            chart_data, current_latest_date, target_data, filter_code, para_style_normal_center
        )
        dept_ward_common_style = [
            ('FONTNAME', (0,0), (-1,-1), REPORTLAB_FONT_NAME), ('GRID', (0,0), (-1,-1), 0.5, colors.black),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'), ('ALIGN', (0,0), (-1,-1), 'CENTER'),
            ('FONTSIZE', (0,0), (-1,0), 8), ('FONTSIZE', (0,1), (-1,-1), 7), ('TEXTCOLOR', (0,0), (-1,0), colors.black),
        ]
        is_ward_pdf = "ç—…æ£Ÿåˆ¥" in title_prefix; is_dept_pdf = "è¨ºç™‚ç§‘åˆ¥" in title_prefix
        
        # ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«
        if (is_ward_pdf and not is_dept_pdf) or (not is_ward_pdf and not is_dept_pdf) :
            if generated_ward_table_data and len(generated_ward_table_data) > 1:
                elements.append(PageBreak()); elements.append(Paragraph(report_title_text, ja_style)); elements.append(Spacer(1, 5*mm))
                elements.append(Paragraph("ç—…æ£Ÿåˆ¥ å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰å¹³å‡", ja_heading2))
                num_cols = len(generated_ward_table_data[0])
                period_count = len(period_labels_dept_ward) if period_labels_dept_ward else 0
                col_widths_ward = [page_width * 0.12] + [(page_width * 0.70) / period_count if period_count > 0 else 0] * period_count + [page_width * 0.09] * 2
                if num_cols != len(col_widths_ward) and num_cols > 0: col_widths_ward = [page_width/num_cols] * num_cols
                elements.append(Table(generated_ward_table_data, colWidths=col_widths_ward, style=TableStyle(dept_ward_common_style + [('BACKGROUND', (0,0), (-1,0), colors.lightgrey)])))
                elements.append(Spacer(1, 4*mm))
        
        # è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«
        if (is_dept_pdf and not is_ward_pdf) or (not is_ward_pdf and not is_dept_pdf) :
            if generated_dept_table_data and len(generated_dept_table_data) > 1:
                # ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ãªã‘ã‚Œã°æ”¹ãƒšãƒ¼ã‚¸
                if not ((is_ward_pdf and not is_dept_pdf) or (not is_ward_pdf and not is_dept_pdf and generated_ward_table_data and len(generated_ward_table_data) > 1)):
                    elements.append(PageBreak())
                elements.append(Paragraph(report_title_text, ja_style)); elements.append(Spacer(1, 5*mm))
                elements.append(Paragraph("è¨ºç™‚ç§‘åˆ¥ å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰å¹³å‡", ja_heading2))
                num_cols = len(generated_dept_table_data[0])
                period_count = len(period_labels_dept_ward) if period_labels_dept_ward else 0
                col_widths_dept = [page_width * 0.12] + [(page_width * 0.70) / period_count if period_count > 0 else 0] * period_count + [page_width * 0.09] * 2
                if num_cols != len(col_widths_dept) and num_cols > 0: col_widths_dept = [page_width/num_cols] * num_cols
                elements.append(Table(generated_dept_table_data, colWidths=col_widths_dept, style=TableStyle(dept_ward_common_style + [('BACKGROUND', (0,0), (-1,0), colors.lightcyan)])))
                elements.append(Spacer(1, 4*mm))

    elements.append(Spacer(1, 8*mm))
    elements.append(Paragraph(f"ä½œæˆæ—¥æ™‚: {today_str}", normal_ja))
    
    try:
        doc.build(elements)
    except Exception as e:
        print(f"âŒ PDFæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼ ({title_prefix}): {e}")
        import traceback
        print(traceback.format_exc())
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚ãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™ã‹ã€Noneã‚’è¿”ã™ã‹æ¤œè¨
        buffer.seek(0) # ç©ºã®ãƒãƒƒãƒ•ã‚¡ã‚„éƒ¨åˆ†çš„ãªãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™å¯èƒ½æ€§
        return buffer # ã¾ãŸã¯ return None
        
    buffer.seek(0)
    gc.collect()
    
    # print(f"ğŸ”§ PDFç”Ÿæˆå®Œäº† - {title_prefix} (æ‰€è¦æ™‚é–“: {time.time() - pdf_start_time:.2f}ç§’)")
    return buffer

# create_landscape_pdf ã‚‚åŒæ§˜ã«ä¿®æ­£
def create_landscape_pdf(
    forecast_df, df_weekday, df_holiday, df_all_avg=None,
    chart_data=None, title_prefix="å…¨ä½“", latest_date=None,
    target_data=None, filter_code="å…¨ä½“", graph_days=None,
    alos_chart_buffers=None,
    patient_chart_buffers=None,
    dual_axis_chart_buffers=None,
    allowed_graph_days=None  # ğŸ”§ ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ­£ã—ãä½¿ç”¨ã™ã‚‹
):
    pdf_start_time = time.time()
    elements = []
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=landscape(A4),
                            leftMargin=12*mm, rightMargin=12*mm,
                            topMargin=12*mm, bottomMargin=12*mm)
    
    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name='Normal_JP_Land', parent=styles['Normal'], fontName=REPORTLAB_FONT_NAME, fontSize=7.5, leading=9))
    styles.add(ParagraphStyle(name='Heading1_JP_Land', parent=styles['Heading1'], fontName=REPORTLAB_FONT_NAME, fontSize=13, spaceAfter=3*mm, leading=15))
    styles.add(ParagraphStyle(name='Heading2_JP_Land', parent=styles['Heading2'], fontName=REPORTLAB_FONT_NAME, fontSize=10, spaceAfter=2*mm, leading=12))
    styles.add(ParagraphStyle(name='Normal_Center_JP_Land', parent=styles['Normal_JP_Land'], alignment=TA_CENTER, fontSize=6.5, leading=8))

    ja_style_land = styles['Heading1_JP_Land']
    ja_heading2_land = styles['Heading2_JP_Land']
    normal_ja_land = styles['Normal_JP_Land']
    para_style_normal_center_land = styles['Normal_Center_JP_Land']

    current_latest_date = latest_date if latest_date else pd.Timestamp.now().normalize()
    if isinstance(current_latest_date, str): current_latest_date = pd.Timestamp(current_latest_date)
    data_date_str = current_latest_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
    today_str = pd.Timestamp.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    report_title_text = f"å…¥é™¢æ‚£è€…æ•°äºˆæ¸¬ - {title_prefix}ï¼ˆãƒ‡ãƒ¼ã‚¿åŸºæº–æ—¥: {data_date_str}ï¼‰"
    elements.append(Paragraph(report_title_text, ja_style_land))
    elements.append(Spacer(1, 3*mm))
    page_width_land, page_height_land = landscape(A4)
    content_width_land = page_width_land - doc.leftMargin - doc.rightMargin
    content_height_land = page_height_land - doc.topMargin - doc.bottomMargin
    graphs_on_current_page = 0
    max_graphs_per_page_land = 2 # æ¨ªå‘ãã®å ´åˆã‚‚1ãƒšãƒ¼ã‚¸2ã‚°ãƒ©ãƒ•æƒ³å®š

    # ğŸ”§ è¨±å¯ã•ã‚ŒãŸæ—¥æ•°ã®è¨­å®šã‚’ä¿®æ­£
    if not allowed_graph_days: # None ã¾ãŸã¯ç©ºã®ãƒªã‚¹ãƒˆã®å ´åˆ
        current_allowed_graph_days = ["90"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Fast Modeç›¸å½“
        print(f"âš ï¸ æ¨ªå‘ãPDFç”Ÿæˆ ({title_prefix}): allowed_graph_days ãŒæŒ‡å®šã•ã‚Œãªã‹ã£ãŸã‹ç©ºã®ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® ['90'] æ—¥ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    else:
        current_allowed_graph_days = [str(d) for d in allowed_graph_days]
    
    print(f"ğŸ”§ æ¨ªå‘ãPDFç”Ÿæˆ ({title_prefix}): create_landscape_pdf é–¢æ•°ãŒä½¿ç”¨ã™ã‚‹ã‚°ãƒ©ãƒ•æ—¥æ•°: {current_allowed_graph_days}")
    
    # ğŸ”§ ã‚°ãƒ©ãƒ•ãƒãƒƒãƒ•ã‚¡ã®æ¤œè¨¼ã¨é‡è¤‡é™¤å»
    validated_alos_buffers = validate_and_deduplicate_chart_buffers(
        alos_chart_buffers, "ALOSã‚°ãƒ©ãƒ•(æ¨ªå‘ã)", current_allowed_graph_days
    ) if alos_chart_buffers else {}
    
    validated_patient_buffers = {}
    if patient_chart_buffers:
        for chart_type, buffers in patient_chart_buffers.items():
            validated_patient_buffers[chart_type] = validate_and_deduplicate_chart_buffers(
                buffers, f"æ‚£è€…æ•°æ¨ç§»ã‚°ãƒ©ãƒ•(æ¨ªå‘ã)({chart_type})", current_allowed_graph_days
            )
    
    validated_dual_axis_buffers = validate_and_deduplicate_chart_buffers(
        dual_axis_chart_buffers, "äºŒè»¸ã‚°ãƒ©ãƒ•(æ¨ªå‘ã)", current_allowed_graph_days
    ) if dual_axis_chart_buffers else {}
    
    # ã‚°ãƒ©ãƒ•è¿½åŠ å‡¦ç† (create_pdfã¨åŒæ§˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã§)
    all_graph_types_to_process_land = []
    if validated_alos_buffers:
        all_graph_types_to_process_land.append(
            ("ALOS", validated_alos_buffers, f"å¹³å‡åœ¨é™¢æ—¥æ•°ã¨å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã®æ¨ç§»ï¼ˆç›´è¿‘%sæ—¥é–“ï¼‰")
        )
    if validated_patient_buffers:
        type_name_map = {"all": "å…¨æ—¥", "weekday": "å¹³æ—¥", "holiday": "ä¼‘æ—¥"}
        for chart_type_key in ["all", "weekday", "holiday"]: # è¡¨ç¤ºé †ã‚’å›ºå®š
            day_buffers_dict = validated_patient_buffers.get(chart_type_key, {})
            if day_buffers_dict:
                display_name = type_name_map.get(chart_type_key, chart_type_key.capitalize())
                all_graph_types_to_process_land.append(
                    (f"æ‚£è€…æ•°æ¨ç§»_{chart_type_key}", day_buffers_dict, f"{display_name} å…¥é™¢æ‚£è€…æ•°æ¨ç§»ï¼ˆç›´è¿‘%sæ—¥é–“ï¼‰")
                )
    if validated_dual_axis_buffers:
        all_graph_types_to_process_land.append(
            ("äºŒè»¸", validated_dual_axis_buffers, f"æ‚£è€…ç§»å‹•ã¨åœ¨é™¢æ•°ã®æ¨ç§»ï¼ˆç›´è¿‘%sæ—¥é–“ï¼‰")
        )

    for graph_name, buffers_dict, title_template in all_graph_types_to_process_land:
        sorted_buffer_items = sorted(buffers_dict.items(), key=lambda item: int(item[0]))
        
        for days_val_str, chart_buffer_bytes in sorted_buffer_items:
            if graphs_on_current_page >= max_graphs_per_page_land:
                elements.append(PageBreak())
                elements.append(Paragraph(report_title_text, ja_style_land))
                elements.append(Spacer(1, 3*mm))
                graphs_on_current_page = 0
                
            if chart_buffer_bytes:
                try:
                    if isinstance(chart_buffer_bytes, bytes):
                        img_buf = BytesIO(chart_buffer_bytes)
                    elif hasattr(chart_buffer_bytes, 'getvalue'):
                        img_buf = chart_buffer_bytes
                    else:
                        print(f"âŒ {graph_name}ã‚°ãƒ©ãƒ•(æ¨ª) ({days_val_str}æ—¥) ã®ãƒãƒƒãƒ•ã‚¡ã‚¿ã‚¤ãƒ—ãŒä¸æ­£: {type(chart_buffer_bytes)}")
                        continue
                    
                    img_buf.seek(0)
                    elements.append(Paragraph(title_template % days_val_str, ja_heading2_land))
                    elements.append(Spacer(1, 1*mm))
                    # æ¨ªå‘ãPDFã§ã®ç”»åƒã‚µã‚¤ã‚ºèª¿æ•´ (ä¾‹: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å¹…ã®90%, é«˜ã•ã¯ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”0.4)
                    elements.append(Image(img_buf, width=content_width_land*0.9, height=(content_width_land*0.9)*0.4)) 
                    elements.append(Spacer(1, 2*mm))
                    graphs_on_current_page += 1
                except Exception as e:
                    print(f"âŒ {graph_name}ã‚°ãƒ©ãƒ•(æ¨ª)è¿½åŠ ã‚¨ãƒ©ãƒ¼ ({title_prefix}, {days_val_str}æ—¥): {e}")
            else:
                print(f"â„¹ï¸ {graph_name}ã‚°ãƒ©ãƒ•(æ¨ª)ã®ãƒãƒƒãƒ•ã‚¡ãŒç©ºã§ã™ ({title_prefix}, {days_val_str}æ—¥)")
        
        if graphs_on_current_page > 0 and graph_name != all_graph_types_to_process_land[-1][0]:
            if graphs_on_current_page >= max_graphs_per_page_land:
                pass
            elif graphs_on_current_page > 0:
                elements.append(PageBreak())
                elements.append(Paragraph(report_title_text, ja_style_land))
                elements.append(Spacer(1, 3*mm))
                graphs_on_current_page = 0

    if graphs_on_current_page > 0: # æœ€å¾Œã®ã‚°ãƒ©ãƒ•ã‚»ãƒƒãƒˆã®å¾Œ
        elements.append(PageBreak())
        elements.append(Paragraph(report_title_text, ja_style_land))
        elements.append(Spacer(1, 3*mm))

    common_table_style_land_cmds = [
        ('FONTNAME', (0,0), (-1,-1), REPORTLAB_FONT_NAME),('GRID', (0,0), (-1,-1), 0.5, colors.black),
        ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),('ALIGN', (0,0), (-1,0), 'CENTER'), 
        ('ALIGN', (1,1), (-1,-1), 'RIGHT'), ('ALIGN', (0,1), (0,-1), 'LEFT'),   
        ('FONTSIZE', (0,0), (-1,0), 8), ('FONTSIZE', (0,1), (-1,-1), 7.5),   
        ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke), ('LEFTPADDING', (0,0), (-1,-1), 1.5*mm), 
        ('RIGHTPADDING', (0,0), (-1,-1), 1.5*mm),
    ]
    if df_all_avg is not None and not df_all_avg.empty:
        elements.append(Paragraph("å…¨æ—¥å¹³å‡å€¤", ja_heading2_land))
        header = [df_all_avg.index.name if df_all_avg.index.name else "åŒºåˆ†"] + df_all_avg.columns.tolist()
        table_data = [header] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in df_all_avg.iterrows()]
        num_cols = len(header); col_widths = [content_width_land*0.15] + [(content_width_land*0.85)/(num_cols-1 if num_cols > 1 else 1)]*(num_cols-1)
        elements.append(Table(table_data, colWidths=col_widths, style=TableStyle(common_table_style_land_cmds + [('BACKGROUND', (0,0), (-1,0), colors.green)])))
        elements.append(Spacer(1, 2*mm))

    if forecast_df is not None and not forecast_df.empty:
        elements.append(Paragraph("åœ¨é™¢æ‚£è€…æ•°äºˆæ¸¬", ja_heading2_land))
        fc_df_mod = forecast_df.copy()
        if "å¹´é–“å¹³å‡äººæ—¥ï¼ˆå®Ÿç¸¾ï¼‹äºˆæ¸¬ï¼‰" in fc_df_mod.columns: fc_df_mod.rename(columns={"å¹´é–“å¹³å‡äººæ—¥ï¼ˆå®Ÿç¸¾ï¼‹äºˆæ¸¬ï¼‰": "å¹´åº¦äºˆæ¸¬"}, inplace=True)
        if "å»¶ã¹äºˆæ¸¬äººæ—¥" in fc_df_mod.columns: fc_df_mod.drop(columns=["å»¶ã¹äºˆæ¸¬äººæ—¥"], inplace=True)
        header = [fc_df_mod.index.name if fc_df_mod.index.name else "åŸºæº–"] + fc_df_mod.columns.tolist()
        table_data = [header] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in fc_df_mod.iterrows()]
        num_cols = len(header); col_widths = [content_width_land*0.2] + [(content_width_land*0.8)/(num_cols-1 if num_cols > 1 else 1)]*(num_cols-1)
        elements.append(Table(table_data, colWidths=col_widths, style=TableStyle(common_table_style_land_cmds + [('BACKGROUND', (0,0), (-1,0), colors.blue)])))
        elements.append(Spacer(1, 2*mm))

    # å¹³æ—¥ãƒ»ä¼‘æ—¥ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‰ã«æ”¹ãƒšãƒ¼ã‚¸
    if (df_weekday is not None and not df_weekday.empty) or \
       (df_holiday is not None and not df_holiday.empty):
        elements.append(PageBreak())
        elements.append(Paragraph(report_title_text, ja_style_land))
        elements.append(Spacer(1, 3*mm))
        
    left_col_elements, right_col_elements = [], []
    table_half_width = content_width_land * 0.48 # å·¦å³ã®ãƒ†ãƒ¼ãƒ–ãƒ«å¹…
    
    if df_weekday is not None and not df_weekday.empty:
        left_col_elements.append(Paragraph("å¹³æ—¥å¹³å‡å€¤", ja_heading2_land))
        header_wd = [df_weekday.index.name if df_weekday.index.name else "åŒºåˆ†"] + df_weekday.columns.tolist()
        table_data_wd = [header_wd] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in df_weekday.iterrows()]
        num_cols_wd = len(header_wd); col_widths_wd = [table_half_width*0.25] + [(table_half_width*0.75)/(num_cols_wd-1 if num_cols_wd > 1 else 1)]*(num_cols_wd-1)
        left_col_elements.append(Table(table_data_wd, colWidths=col_widths_wd, style=TableStyle(common_table_style_land_cmds + [('BACKGROUND', (0,0), (-1,0), colors.teal)])))
    
    if df_holiday is not None and not df_holiday.empty:
        right_col_elements.append(Paragraph("ä¼‘æ—¥å¹³å‡å€¤", ja_heading2_land))
        header_hd = [df_holiday.index.name if df_holiday.index.name else "åŒºåˆ†"] + df_holiday.columns.tolist()
        table_data_hd = [header_hd] + [[str(idx)] + [f"{x:.1f}" if isinstance(x,(float,int)) and pd.notna(x) else (str(x) if pd.notna(x) else "-") for x in row] for idx, row in df_holiday.iterrows()]
        num_cols_hd = len(header_hd); col_widths_hd = [table_half_width*0.25] + [(table_half_width*0.75)/(num_cols_hd-1 if num_cols_hd > 1 else 1)]*(num_cols_hd-1)
        right_col_elements.append(Table(table_data_hd, colWidths=col_widths_hd, style=TableStyle(common_table_style_land_cmds + [('BACKGROUND', (0,0), (-1,0), colors.orange)])))
    
    if left_col_elements or right_col_elements:
        # Tableã®ã‚»ãƒ«ã«ç›´æ¥ãƒªã‚¹ãƒˆã‚’æ¸¡ã™
        elements.append(Table([[left_col_elements, right_col_elements]], 
                                colWidths=[table_half_width, content_width_land - table_half_width - 2*mm], # éš™é–“ã‚’è€ƒæ…®
                                style=TableStyle([('VALIGN', (0,0), (-1,-1), 'TOP')]))) # ä¸Šæƒãˆ
    elements.append(Spacer(1, 2*mm))


    if chart_data is not None and not chart_data.empty:
        generated_ward_table_data, generated_dept_table_data, period_labels_dept_ward = create_department_tables(
            chart_data, current_latest_date, target_data, filter_code, para_style_normal_center_land
        )
        dept_ward_style_land = [
            ('FONTNAME', (0,0), (-1,-1), REPORTLAB_FONT_NAME), ('GRID', (0,0), (-1,-1), 0.5, colors.black),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'), ('ALIGN', (0,0), (-1,-1), 'CENTER'),
            ('FONTSIZE', (0,0), (-1,0), 7), ('FONTSIZE', (0,1), (-1,-1), 6.5), ('TEXTCOLOR', (0,0), (-1,0), colors.black),
        ]
        is_ward_pdf = "ç—…æ£Ÿåˆ¥" in title_prefix; is_dept_pdf = "è¨ºç™‚ç§‘åˆ¥" in title_prefix
        
        if (is_ward_pdf and not is_dept_pdf) or (not is_ward_pdf and not is_dept_pdf) : # ç—…æ£ŸPDF ã¾ãŸã¯ å…¨ä½“PDF ã®å ´åˆ
            if generated_ward_table_data and len(generated_ward_table_data) > 1:
                elements.append(PageBreak()); elements.append(Paragraph(report_title_text, ja_style_land)); elements.append(Spacer(1, 3*mm))
                elements.append(Paragraph("ç—…æ£Ÿåˆ¥ å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰å¹³å‡", ja_heading2_land))
                num_cols = len(generated_ward_table_data[0]); period_count = len(period_labels_dept_ward) if period_labels_dept_ward else 0
                col_widths_w = [content_width_land*0.10] + [(content_width_land*0.72)/period_count if period_count > 0 else 0]*period_count + [content_width_land*0.09]*2
                if num_cols != len(col_widths_w) and num_cols > 0: col_widths_w = [content_width_land/num_cols] * num_cols
                elements.append(Table(generated_ward_table_data, colWidths=col_widths_w, style=TableStyle(dept_ward_style_land + [('BACKGROUND', (0,0), (-1,0), colors.lightgrey)])))
                elements.append(Spacer(1, 2*mm))
        
        if (is_dept_pdf and not is_ward_pdf) or (not is_ward_pdf and not is_dept_pdf) : # è¨ºç™‚ç§‘PDF ã¾ãŸã¯ å…¨ä½“PDF ã®å ´åˆ
            if generated_dept_table_data and len(generated_dept_table_data) > 1:
                # ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ãªã‘ã‚Œã°æ”¹ãƒšãƒ¼ã‚¸ (å…¨ä½“PDFã§ç—…æ£Ÿãƒ†ãƒ¼ãƒ–ãƒ«ãŒå…ˆã«å‡ºã¦ã„ã‚‹å ´åˆ)
                needs_page_break_before_dept = True
                if (not is_ward_pdf and not is_dept_pdf) and (generated_ward_table_data and len(generated_ward_table_data) > 1):
                    # å…¨ä½“PDFã§ã€ã‹ã¤ç—…æ£Ÿãƒ†ãƒ¼ãƒ–ãƒ«ãŒæ—¢ã«å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€æ”¹ãƒšãƒ¼ã‚¸æ¸ˆã¿ã¨ã¿ãªã™
                     pass # æ”¹ãƒšãƒ¼ã‚¸ã¯æ—¢ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ã€ç—…æ£Ÿãƒ†ãƒ¼ãƒ–ãƒ«ã®ç›´å¾Œ
                else:
                    elements.append(PageBreak())
                
                elements.append(Paragraph(report_title_text, ja_style_land)); elements.append(Spacer(1, 3*mm))
                elements.append(Paragraph("è¨ºç™‚ç§‘åˆ¥ å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰å¹³å‡", ja_heading2_land))
                num_cols = len(generated_dept_table_data[0]); period_count = len(period_labels_dept_ward) if period_labels_dept_ward else 0
                col_widths_d = [content_width_land*0.10] + [(content_width_land*0.72)/period_count if period_count > 0 else 0]*period_count + [content_width_land*0.09]*2
                if num_cols != len(col_widths_d) and num_cols > 0: col_widths_d = [content_width_land/num_cols] * num_cols
                elements.append(Table(generated_dept_table_data, colWidths=col_widths_d, style=TableStyle(dept_ward_style_land + [('BACKGROUND', (0,0), (-1,0), colors.lightcyan)])))
                elements.append(Spacer(1, 2*mm))

    elements.append(Spacer(1, 5*mm))
    elements.append(Paragraph(f"ä½œæˆæ—¥æ™‚: {today_str}", normal_ja_land))
    
    try:
        doc.build(elements)
    except Exception as e:
        print(f"âŒ æ¨ªå‘ãPDFæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼ ({title_prefix}): {e}")
        import traceback
        print(traceback.format_exc())
        buffer.seek(0)
        return buffer # ã¾ãŸã¯ return None
        
    buffer.seek(0)
    gc.collect()
    
    # print(f"ğŸ”§ æ¨ªå‘ãPDFç”Ÿæˆå®Œäº† - {title_prefix} (æ‰€è¦æ™‚é–“: {time.time() - pdf_start_time:.2f}ç§’)")
    return buffer


# --- éƒ¨é–€åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆé–¢æ•° (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—ã¨ä»®å®š) ---
def create_department_tables(chart_data, latest_date, target_data=None, filter_code=None, para_style=None):
    dept_tbl_start_time = time.time()
    if chart_data is None or chart_data.empty or latest_date is None:
        return [], [], []

    if not pd.api.types.is_datetime64_any_dtype(chart_data['æ—¥ä»˜']):
        try: 
            chart_data['æ—¥ä»˜'] = pd.to_datetime(chart_data['æ—¥ä»˜'])
        except Exception: 
            print("Error: Could not convert 'æ—¥ä»˜' to datetime in create_department_tables.")
            return [], [], []
    if not isinstance(latest_date, pd.Timestamp): 
        try:
            latest_date = pd.Timestamp(latest_date)
        except Exception:
            print(f"Error: Could not convert latest_date '{latest_date}' to Timestamp.")
            return [], [], []


    current_year_start_month = 4 # å¹´åº¦é–‹å§‹æœˆ (4æœˆ)
    if latest_date.month < current_year_start_month:
        current_fiscal_year_start = pd.Timestamp(year=latest_date.year - 1, month=current_year_start_month, day=1)
    else:
        current_fiscal_year_start = pd.Timestamp(year=latest_date.year, month=current_year_start_month, day=1)
    current_fiscal_year_end_for_data = latest_date # ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°æ—¥ã¾ã§
    
    previous_fiscal_year_start = current_fiscal_year_start - pd.DateOffset(years=1)
    previous_fiscal_year_end = current_fiscal_year_start - pd.Timedelta(days=1) # å‰å¹´åº¦ã®æœ€çµ‚æ—¥

    period_definitions = {
        "ç›´è¿‘7æ—¥": (latest_date - pd.Timedelta(days=6), latest_date),
        "ç›´è¿‘14æ—¥": (latest_date - pd.Timedelta(days=13), latest_date),
        "ç›´è¿‘30æ—¥": (latest_date - pd.Timedelta(days=29), latest_date),
        "ç›´è¿‘60æ—¥": (latest_date - pd.Timedelta(days=59), latest_date),
        f"{current_fiscal_year_start.year}å¹´åº¦": (current_fiscal_year_start, current_fiscal_year_end_for_data),
        f"{previous_fiscal_year_start.year}å¹´åº¦": (previous_fiscal_year_start, previous_fiscal_year_end),
    }
    period_labels_for_data = list(period_definitions.keys())
    period_name_for_achievement = "ç›´è¿‘30æ—¥" # é”æˆç‡è¨ˆç®—ã®åŸºæº–æœŸé–“
    
    if para_style is None: # ReportLabã®ParagraphStyleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æœŸå¾…
        styles_default = getSampleStyleSheet()
        # ãƒ•ã‚©ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€ãªã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        font_name_to_use = REPORTLAB_FONT_NAME
        try:
            pdfmetrics.getFont(font_name_to_use)
        except KeyError:
            print(f"Warning: Font '{font_name_to_use}' not found in ReportLab. Falling back to Helvetica.")
            font_name_to_use = 'Helvetica' # ReportLabã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã®ä¸€ã¤
            
        para_style = ParagraphStyle('ParaNormalCenterDefault_Dept', 
                                    parent=styles_default['Normal'], 
                                    fontName=font_name_to_use, 
                                    fontSize=6.5, 
                                    alignment=TA_CENTER, 
                                    leading=7)

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒ©ãƒ™ãƒ«ã«æ”¹è¡Œã‚’æŒ¿å…¥ (ReportLabã®Paragraphã¯HTMLãƒ©ã‚¤ã‚¯ãª<br/>ã‚¿ã‚°ã§æ”¹è¡Œå¯èƒ½)
    period_labels_for_header = [Paragraph(label.replace("ç›´è¿‘", "ç›´è¿‘<br/>").replace("å¹´åº¦", "<br/>å¹´åº¦"), para_style) for label in period_labels_for_data]

    ward_codes_unique = sorted(chart_data["ç—…æ£Ÿã‚³ãƒ¼ãƒ‰"].astype(str).unique()) if "ç—…æ£Ÿã‚³ãƒ¼ãƒ‰" in chart_data.columns else []
    dept_names_original = sorted(chart_data["è¨ºç™‚ç§‘å"].unique()) if "è¨ºç™‚ç§‘å" in chart_data.columns else []
    dept_names_to_process = dept_names_original # ç‰¹ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒãªã‘ã‚Œã°ãã®ã¾ã¾
    
    # è¡¨ç¤ºåãƒãƒƒãƒ”ãƒ³ã‚° (target_data ã‹ã‚‰å–å¾—ã€ãªã‘ã‚Œã°ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç”Ÿæˆ)
    ward_display_names = {}
    if target_data is not None and not target_data.empty and 'éƒ¨é–€ã‚³ãƒ¼ãƒ‰' in target_data.columns and 'éƒ¨é–€å' in target_data.columns:
        # 'éƒ¨é–€ã‚³ãƒ¼ãƒ‰'ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
        unique_target_wards = target_data[['éƒ¨é–€ã‚³ãƒ¼ãƒ‰', 'éƒ¨é–€å']].drop_duplicates('éƒ¨é–€ã‚³ãƒ¼ãƒ‰')
        ward_display_map_from_target = pd.Series(unique_target_wards.éƒ¨é–€å.values, index=unique_target_wards.éƒ¨é–€ã‚³ãƒ¼ãƒ‰.astype(str)).to_dict()
    else:
        ward_display_map_from_target = {}

    for ward_code in ward_codes_unique:
        display_name = ward_display_map_from_target.get(ward_code)
        if display_name and pd.notna(display_name):
            ward_display_names[ward_code] = display_name
        else: # target_dataã«ãªã„ã‹ã€éƒ¨é–€åãŒNaNã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            match = re.match(r'0*(\d+)([A-Za-z]*)', ward_code) # å…ˆé ­ã®0ã‚’é™¤å»
            if match: 
                ward_display_names[ward_code] = f"{match.group(1)}{match.group(2)}ç—…æ£Ÿ"
            else: 
                ward_display_names[ward_code] = ward_code # ãƒãƒƒãƒã—ãªã„å ´åˆã¯ãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨

    # é›†è¨ˆç”¨è¾æ›¸
    ward_metrics = {ward_code: {} for ward_code in ward_codes_unique}
    dept_metrics = {dept_name: {} for dept_name in dept_names_to_process}

    # æœŸé–“åˆ¥é›†è¨ˆ
    for period_label, (start_dt_period, end_dt_period) in period_definitions.items():
        if start_dt_period > end_dt_period: # å‰å¹´åº¦ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆãªã©
            continue
        period_data_df = chart_data[(chart_data["æ—¥ä»˜"] >= start_dt_period) & (chart_data["æ—¥ä»˜"] <= end_dt_period)]
        if period_data_df.empty: 
            continue
        
        num_days_in_period_calc = period_data_df['æ—¥ä»˜'].nunique() # æœŸé–“å†…ã®å®Ÿãƒ‡ãƒ¼ã‚¿æ—¥æ•°
        if num_days_in_period_calc == 0: 
            continue
            
        # ç—…æ£Ÿåˆ¥é›†è¨ˆ
        for ward_code in ward_codes_unique:
            ward_data_df = period_data_df[period_data_df["ç—…æ£Ÿã‚³ãƒ¼ãƒ‰"].astype(str) == ward_code]
            if not ward_data_df.empty and 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰' in ward_data_df.columns:
                # æ—¥ä»˜ã”ã¨ã«åˆè¨ˆã—ã¦ã‹ã‚‰æœŸé–“ã§åˆè¨ˆ (é‡è¤‡æ—¥ãŒã‚ã‚‹å ´åˆã«å‚™ãˆã‚‹)
                total_patient_days_val = ward_data_df.groupby('æ—¥ä»˜')['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰'].sum().sum()
                avg_daily_census_val = total_patient_days_val / num_days_in_period_calc if num_days_in_period_calc > 0 else np.nan
                ward_metrics[ward_code][period_label] = avg_daily_census_val
            else: 
                ward_metrics[ward_code][period_label] = np.nan # ãƒ‡ãƒ¼ã‚¿ãªã—

        # è¨ºç™‚ç§‘åˆ¥é›†è¨ˆ
        for dept_name in dept_names_to_process:
            dept_data_df = period_data_df[period_data_df["è¨ºç™‚ç§‘å"] == dept_name]
            if not dept_data_df.empty and 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰' in dept_data_df.columns:
                total_patient_days_val = dept_data_df.groupby('æ—¥ä»˜')['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰'].sum().sum()
                avg_daily_census_val = total_patient_days_val / num_days_in_period_calc if num_days_in_period_calc > 0 else np.nan
                dept_metrics[dept_name][period_label] = avg_daily_census_val
            else: 
                dept_metrics[dept_name][period_label] = np.nan
    
    # ç›®æ¨™å€¤ã¨é”æˆç‡ã®å–å¾— (æ–°ã—ã„ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã«å¯¾å¿œ)
    target_dict_cache_local = {} # é–¢æ•°å†…ã§ã®ç°¡æ˜“ã‚­ãƒ£ãƒƒã‚·ãƒ¥

    def get_targets_achievements_new_format(items_list, metrics_data_dict, target_data_df, achievement_period_name=period_name_for_achievement):
        targets_map = {}
        achievements_map = {}
        
        if target_data_df is None or target_data_df.empty:
            return targets_map, achievements_map

        # å¿…è¦ãªåˆ—ã‚’ç¢ºèª
        required_cols_new = ['éƒ¨é–€ã‚³ãƒ¼ãƒ‰', 'æŒ‡æ¨™ã‚¿ã‚¤ãƒ—', 'æœŸé–“åŒºåˆ†', 'ç›®æ¨™å€¤']
        required_cols_old = ['éƒ¨é–€ã‚³ãƒ¼ãƒ‰', 'åŒºåˆ†', 'ç›®æ¨™å€¤'] # å¤ã„å½¢å¼
        
        target_data_df_local = target_data_df.copy() # å…ƒã®DFã‚’å¤‰æ›´ã—ãªã„

        is_new_format = all(col in target_data_df_local.columns for col in required_cols_new)
        is_old_format = all(col in target_data_df_local.columns for col in required_cols_old)

        if is_new_format:
            # print("Using new target file format.")
            # ã€Œæ—¥å¹³å‡åœ¨é™¢æ‚£è€…æ•°ã€ã¾ãŸã¯ã€Œåœ¨é™¢æ‚£è€…æ•°ã€ã«é–¢é€£ã™ã‚‹ã€Œå…¨æ—¥ã€ã®ç›®æ¨™å€¤ã‚’å–å¾—
            census_targets_df = target_data_df_local[
                (target_data_df_local['æŒ‡æ¨™ã‚¿ã‚¤ãƒ—'].astype(str).str.contains('æ—¥å¹³å‡åœ¨é™¢æ‚£è€…æ•°|åœ¨é™¢æ‚£è€…æ•°', case=False, na=False)) &
                (target_data_df_local['æœŸé–“åŒºåˆ†'].astype(str) == 'å…¨æ—¥') & # å…¨æ—¥ã®ç›®æ¨™å€¤ã®ã¿
                (pd.notna(target_data_df_local['éƒ¨é–€ã‚³ãƒ¼ãƒ‰'])) &
                (pd.notna(target_data_df_local['ç›®æ¨™å€¤']))
            ]
            if not census_targets_df.empty:
                # éƒ¨é–€ã‚³ãƒ¼ãƒ‰ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦é‡è¤‡ã‚’å‰Šé™¤ã—ã€è¾æ›¸ã‚’ä½œæˆ
                target_mapping = dict(zip(census_targets_df['éƒ¨é–€ã‚³ãƒ¼ãƒ‰'].astype(str), census_targets_df['ç›®æ¨™å€¤'].astype(float)))
                
                for item_id in items_list:
                    item_id_str = str(item_id)
                    target_val = target_mapping.get(item_id_str)
                    if target_val is not None:
                        targets_map[item_id] = target_val
                        actual_val = metrics_data_dict.get(item_id, {}).get(achievement_period_name)
                        if pd.notna(actual_val) and target_val > 0:
                            achievements_map[item_id] = (actual_val / target_val) * 100
        elif is_old_format:
            # print("Using old target file format.")
            # å¤ã„å½¢å¼ã®å‡¦ç†ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã«è¿‘ã„ï¼‰
            old_census_targets_df = target_data_df_local[
                (target_data_df_local['åŒºåˆ†'].astype(str) == 'å…¨æ—¥') & # å…¨æ—¥ã®ç›®æ¨™å€¤ã®ã¿
                (pd.notna(target_data_df_local['éƒ¨é–€ã‚³ãƒ¼ãƒ‰'])) &
                (pd.notna(target_data_df_local['ç›®æ¨™å€¤']))
            ]
            if not old_census_targets_df.empty:
                target_mapping = dict(zip(old_census_targets_df['éƒ¨é–€ã‚³ãƒ¼ãƒ‰'].astype(str), old_census_targets_df['ç›®æ¨™å€¤'].astype(float)))

                for item_id in items_list:
                    item_id_str = str(item_id)
                    target_val = target_mapping.get(item_id_str)
                    if target_val is not None:
                        targets_map[item_id] = target_val
                        actual_val = metrics_data_dict.get(item_id, {}).get(achievement_period_name)
                        if pd.notna(actual_val) and target_val > 0:
                            achievements_map[item_id] = (actual_val / target_val) * 100
        else:
            print(f"Target file columns do not match known formats. Available columns: {list(target_data_df_local.columns)}")

        return targets_map, achievements_map

    ward_targets, ward_achievements = get_targets_achievements_new_format(ward_codes_unique, ward_metrics, target_data)
    dept_targets, dept_achievements = get_targets_achievements_new_format(dept_names_to_process, dept_metrics, target_data)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºé †ã®ã‚½ãƒ¼ãƒˆ (é”æˆç‡ > ç›®æ¨™å€¤ã‚ã‚Š > ç›®æ¨™å€¤ãªã—)
    def sort_entities_for_table(entities, achievements_dict, targets_dict, display_names_dict=None):
        # display_names_dictã¯ã‚½ãƒ¼ãƒˆã‚­ãƒ¼ã«ã¯ç›´æ¥ä½¿ã‚ãªã„ãŒã€å…ƒã®entity IDã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ãƒ©ãƒƒãƒ—ã™ã‚‹
        def get_sort_key(entity_id):
            ach = achievements_dict.get(entity_id, -float('inf')) # é”æˆç‡ãŒãªã„å ´åˆã¯æœ€å¾Œã«
            has_target = entity_id in targets_dict
            # é”æˆç‡ã§é™é †ã€ç›®æ¨™å€¤ã‚ã‚Šã‚’å„ªå…ˆã€æœ€å¾Œã«IDã§æ˜‡é † (æ–‡å­—åˆ—ã¨ã—ã¦)
            return (-ach, not has_target, str(entity_id)) 
            
        return sorted(entities, key=get_sort_key)

    sorted_ward_codes = sort_entities_for_table(ward_codes_unique, ward_achievements, ward_targets, ward_display_names)
    # è¨ºç™‚ç§‘åã¯æ—¢ã«æ–‡å­—åˆ—ãªã®ã§ã€display_names_dictã¯ä¸è¦
    sorted_dept_names = sort_entities_for_table(dept_names_to_process, dept_achievements, dept_targets)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼
    header_items = [Paragraph("éƒ¨é–€", para_style)] + period_labels_for_header + \
                   [Paragraph("ç›®æ¨™å€¤", para_style), Paragraph("é”æˆç‡<br/>(%)", para_style)]
    
    # ç—…æ£Ÿãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    ward_table_data = [header_items]
    for ward_code_val in sorted_ward_codes: # ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨
        display_name_ward = ward_display_names.get(ward_code_val, str(ward_code_val))
        row_items = [Paragraph(display_name_ward, para_style)]
        for period_label_val in period_labels_for_data: 
            val = ward_metrics.get(ward_code_val, {}).get(period_label_val)
            row_items.append(f"{val:.1f}" if pd.notna(val) else "-")
        row_items.append(f"{ward_targets.get(ward_code_val):.1f}" if ward_code_val in ward_targets else "-")
        row_items.append(f"{ward_achievements.get(ward_code_val):.1f}" if ward_code_val in ward_achievements else "-")
        ward_table_data.append(row_items)
    
    # è¨ºç™‚ç§‘ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    dept_table_data = [header_items]
    for dept_name_val in sorted_dept_names: # ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨
        # è¨ºç™‚ç§‘åã¯ãã®ã¾ã¾è¡¨ç¤º
        row_items = [Paragraph(str(dept_name_val), para_style)]
        for period_label_val in period_labels_for_data: 
            val = dept_metrics.get(dept_name_val, {}).get(period_label_val)
            row_items.append(f"{val:.1f}" if pd.notna(val) else "-")
        row_items.append(f"{dept_targets.get(dept_name_val):.1f}" if dept_name_val in dept_targets else "-")
        row_items.append(f"{dept_achievements.get(dept_name_val):.1f}" if dept_name_val in dept_achievements else "-")
        dept_table_data.append(row_items)
    
    # print(f"Department table generation took: {time.time() - dept_tbl_start_time:.2f}s")
    return ward_table_data, dept_table_data, period_labels_for_data